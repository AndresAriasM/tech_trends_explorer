# src/s_curve.py
import streamlit as st
import os
import requests
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import time
from datetime import datetime
import re
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from utils.scopus_builder import scopus_equation_interface, parse_scopus_query
from scipy.optimize import curve_fit
import json
import io
import openpyxl
from openpyxl.styles import Font, Alignment, PatternFill
from openpyxl.utils import get_column_letter

# Definir la funci√≥n sigmoidal al nivel global para que est√© disponible en toda la aplicaci√≥n
def sigmoid(x, L, x0, k):
    """
    Funci√≥n sigmoidal de tres par√°metros.
    """
    return L / (1 + np.exp(-k * (x - x0)))

class ScopusPublicationsAnalyzer:
    """
    Clase para conectarse a la API de Scopus, buscar publicaciones acad√©micas y analizarlas por a√±o
    para crear una curva en S.
    """
    
    def __init__(self, api_key=None):
        """
        Inicializa el analizador.
        
        Args:
            api_key: La clave API de Scopus.
        """
        self.api_key = api_key
        self.base_url = "https://api.elsevier.com/content/search/scopus"
        self.headers = {
            "X-ELS-APIKey": api_key,
            "Accept": "application/json"
        }
        self.publications_by_year = {}
        
    def search_publications(self, query, max_results=1000):
        """
        Busca publicaciones en Scopus utilizando una consulta, sin filtros de a√±o.
        
        Args:
            query: Consulta de b√∫squeda en formato de sintaxis de Scopus
            max_results: N√∫mero m√°ximo de resultados a recuperar
            
        Returns:
            Resultados de la b√∫squeda o None si hay error
        """
        # A√±adir filtro espec√≠fico para excluir patentes
        query_papers = f"({query}) AND NOT (DOCTYPE(pt))"
        
        # Mostrar ecuaci√≥n de b√∫squeda
        st.info(f"üìù Ecuaci√≥n de b√∫squeda (Papers): {query_papers}")
        
        # Configurar par√°metros de b√∫squeda
        base_url = "https://api.elsevier.com/content/search/scopus"
        headers = {
            "X-ELS-APIKey": self.api_key,
            "Accept": "application/json"
        }
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Intentar la b√∫squeda
        try:
            # Verificar si la b√∫squeda funciona
            status_text.text("üîç Verificando si la b√∫squeda funciona...")
            
            response = requests.get(
                base_url,
                headers=headers,
                params={"query": query_papers, "count": 1}
            )
            
            if response.status_code != 200:
                st.error(f"‚ùå Error en la b√∫squeda de papers: {response.status_code}")
                st.code(response.text)
                
                # Probar con una versi√≥n simplificada de la consulta para diagnosticar
                status_text.text("üîç Probando con b√∫squeda simplificada...")
                simple_query = 'TITLE("banana") AND TITLE("flour") AND NOT (DOCTYPE(pt))'
                
                st.info(f"üìù Intentando con: {simple_query}")
                
                response = requests.get(
                    base_url,
                    headers=headers,
                    params={"query": simple_query, "count": 1}
                )
                
                if response.status_code == 200:
                    st.success("‚úÖ La b√∫squeda simplificada funciona")
                    st.info("‚ùó El problema est√° en la complejidad de la ecuaci√≥n original")
                    
                    # Usar la ecuaci√≥n simplificada
                    query_papers = simple_query
                    st.info(f"üìù Nueva ecuaci√≥n de b√∫squeda: {query_papers}")
                else:
                    st.error(f"‚ùå Error tambi√©n con b√∫squeda simplificada: {response.status_code}")
                    st.code(response.text)
                    return None
            
            # Realizar la b√∫squeda con la ecuaci√≥n (original o simplificada)
            status_text.text("üîç Obteniendo resultados completos...")
            
            response = requests.get(
                base_url,
                headers=headers,
                params={"query": query_papers, "count": 25, "sort": "coverDate"}
            )
            
            if response.status_code == 200:
                data = response.json()
                total_results = int(data["search-results"]["opensearch:totalResults"])
                st.success(f"‚úÖ B√∫squeda exitosa: {total_results} papers encontrados")
                
                if total_results == 0:
                    status_text.text("‚ùå No se encontraron papers con esta ecuaci√≥n")
                    return None
                
                # Recopilar todos los resultados
                all_results = []
                params = {"query": query_papers, "count": 25, "start": 0, "sort": "coverDate"}
                
                while params["start"] < min(total_results, max_results):
                    response = requests.get(base_url, headers=headers, params=params)
                    
                    if response.status_code == 200:
                        data = response.json()
                        entries = data["search-results"].get("entry", [])
                        all_results.extend(entries)
                        
                        # Actualizar progreso
                        progress = min(len(all_results) / min(total_results, max_results), 1.0)
                        progress_bar.progress(progress)
                        status_text.text(f"‚è≥ Recuperados {len(all_results)} de {min(total_results, max_results)} papers ({progress*100:.1f}%)...")
                        
                        params["start"] += params["count"]
                        
                        if params["start"] < min(total_results, max_results):
                            time.sleep(0.5)  # peque√±a pausa entre solicitudes
                    else:
                        st.error(f"‚ùå Error al recuperar p√°gina: {response.status_code}")
                        st.code(response.text)
                        break
                
                # Limpieza y mensaje final
                progress_bar.empty()
                
                if all_results:
                    status_text.text(f"‚úÖ Recuperados {len(all_results)} papers en total")
                    return all_results
                else:
                    status_text.text("‚ùå No se pudieron recuperar papers")
                    return None
            else:
                st.error(f"‚ùå Error en la b√∫squeda: {response.status_code}")
                st.code(response.text)
                return None
        except Exception as e:
            st.error(f"‚ùå Error inesperado en b√∫squeda de papers: {str(e)}")
            import traceback
            st.code(traceback.format_exc())
            return None
        
    def categorize_by_year(self, results):
        """
        Categoriza los resultados de publicaciones por a√±o y completa los a√±os faltantes con ceros.
        
        Args:
            results: Lista de resultados de la b√∫squeda
            
        Returns:
            Diccionario con el recuento por a√±o
        """
        publications_by_year = {}
        
        st.text("üìÖ Categorizando publicaciones por a√±o...")
        
        for entry in results:
            # Intentar extraer el a√±o de diferentes campos
            year = None
            
            # M√©todo 1: Del campo prism:coverDate
            if "prism:coverDate" in entry:
                try:
                    date_str = entry["prism:coverDate"]
                    year = datetime.strptime(date_str, "%Y-%m-%d").year
                except (ValueError, TypeError):
                    pass
            
            # M√©todo 2: Del campo prism:publicationDate
            if not year and "prism:publicationDate" in entry:
                try:
                    date_str = entry["prism:publicationDate"]
                    year = datetime.strptime(date_str, "%Y-%m-%d").year
                except (ValueError, TypeError):
                    pass
                    
            # M√©todo 3: Del texto de la fecha de portada
            if not year and "prism:coverDisplayDate" in entry:
                try:
                    year_str = entry["prism:coverDisplayDate"]
                    # Buscar un a√±o en el texto con regex
                    match = re.search(r'(19|20)\d{2}', year_str)
                    if match:
                        year = int(match.group(0))
                except (ValueError, TypeError, AttributeError):
                    pass
            
            # Si no se pudo determinar el a√±o, continuar con la siguiente entrada
            if not year:
                continue
            
            # Incrementar el contador para este a√±o
            publications_by_year[year] = publications_by_year.get(year, 0) + 1
        
        # Completar a√±os faltantes con ceros
        if publications_by_year:
            min_year = min(publications_by_year.keys())
            max_year = max(publications_by_year.keys())
            
            # Crear rango completo de a√±os
            all_years = list(range(min_year, max_year + 1))
            
            # Completar con ceros los a√±os faltantes
            complete_publications = {year: publications_by_year.get(year, 0) for year in all_years}
            
            # Ordenar por a√±o
            self.publications_by_year = dict(sorted(complete_publications.items()))
        else:
            self.publications_by_year = {}
            
        return self.publications_by_year


class PatentDataManager:
    """
    Clase para gestionar datos de patentes cargados manualmente mediante archivos Excel.
    """
    
    @staticmethod
    def create_template(start_year=1920, end_year=None):
        """
        Crea una plantilla Excel para la carga de datos de patentes por a√±o.
        
        Args:
            start_year: A√±o inicial para la plantilla
            end_year: A√±o final para la plantilla (por defecto es el a√±o actual)
        
        Returns:
            BytesIO: Objeto de bytes con el contenido del archivo Excel
        """
        if end_year is None:
            end_year = datetime.now().year
        
        # Crear workbook y hoja
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = "Datos de Patentes"
        
        # A√±adir encabezados con estilo
        ws['A1'] = "A√±o"
        ws['B1'] = "N√∫mero de Patentes"
        ws['C1'] = "Notas/Observaciones"
        
        # Aplicar estilos a los encabezados
        for col in ['A', 'B', 'C']:
            cell = ws[f'{col}1']
            cell.font = Font(bold=True)
            cell.fill = PatternFill(start_color="E0E0E0", end_color="E0E0E0", fill_type="solid")
            cell.alignment = Alignment(horizontal='center')
        
        # Ajustar anchos de columna
        ws.column_dimensions['A'].width = 10
        ws.column_dimensions['B'].width = 20
        ws.column_dimensions['C'].width = 30
        
        # A√±adir filas para cada a√±o
        for i, year in enumerate(range(start_year, end_year + 1), start=2):
            ws[f'A{i}'] = year
            ws[f'B{i}'] = 0  # Valor predeterminado
            
            # Aplicar formato num√©rico a la columna de patentes
            ws[f'B{i}'].number_format = '0'
        
        # A√±adir instrucciones en una nueva hoja
        ws_instructions = wb.create_sheet(title="Instrucciones")
        
        instructions = [
            "INSTRUCCIONES PARA COMPLETAR LA PLANTILLA DE PATENTES",
            "",
            "1. Completa la columna 'N√∫mero de Patentes' con la cantidad de patentes por a√±o.",
            "2. Los datos deben ser valores num√©ricos enteros.",
            "3. No elimines ning√∫n a√±o de la lista.",
            "4. Puedes dejar a√±os con valor 0 si no hay datos disponibles.",
            "5. La columna 'Notas/Observaciones' es opcional y puedes usarla para informaci√≥n adicional.",
            "6. Guarda el archivo cuando hayas completado los datos.",
            "7. Sube el archivo en la aplicaci√≥n para analizar los datos de patentes.",
            "",
            "C√ìMO OBTENER LOS DATOS DE PATENTES:",
            "",
            "- Opci√≥n 1: Busca en la pesta√±a 'Patents' de Scopus y anota el n√∫mero de resultados por a√±o.",
            "- Opci√≥n 2: Utiliza otras bases de datos de patentes como PatentScope, Google Patents, o Espacenet.",
            "- Opci√≥n 3: Consulta informes de oficinas de patentes nacionales o internacionales.",
            "",
            "Nota: Para una an√°lisis preciso, aseg√∫rate de utilizar la misma ecuaci√≥n de b√∫squeda o criterios consistentes para todos los a√±os."
        ]
        
        for i, line in enumerate(instructions, start=1):
            ws_instructions[f'A{i}'] = line
        
        # Ajustar ancho de columna en la hoja de instrucciones
        ws_instructions.column_dimensions['A'].width = 100
        
        # Guardar en un objeto de bytes
        output = io.BytesIO()
        wb.save(output)
        output.seek(0)
        
        return output
    
    @staticmethod
    def load_data(uploaded_file):
        """
        Carga y procesa datos de patentes desde un archivo Excel subido.
        
        Args:
            uploaded_file: Archivo Excel subido mediante st.file_uploader
            
        Returns:
            dict: Diccionario con datos de patentes por a√±o {a√±o: conteo}
        """
        try:
            # Cargar el archivo Excel
            df = pd.read_excel(uploaded_file, sheet_name="Datos de Patentes")
            
            # Verificar que las columnas necesarias existen
            if "A√±o" not in df.columns or "N√∫mero de Patentes" not in df.columns:
                st.error("‚ùå El archivo no tiene el formato esperado. Aseg√∫rate de usar la plantilla proporcionada.")
                return None
            
            # Convertir a diccionario {a√±o: conteo}
            patents_by_year = dict(zip(df["A√±o"], df["N√∫mero de Patentes"]))
            
            # Filtrar a√±os con valores nulos o no num√©ricos
            patents_by_year = {year: int(count) for year, count in patents_by_year.items() 
                              if pd.notna(count) and str(count).replace('.', '', 1).isdigit()}
            
            # Ordenar por a√±o
            patents_by_year = dict(sorted(patents_by_year.items()))
            
            return patents_by_year
            
        except Exception as e:
            st.error(f"‚ùå Error al cargar el archivo: {str(e)}")
            return None


class TechnologyAnalyzer:
    """
    Clase para analizar datos de publicaciones o patentes y generar an√°lisis de curva en S.
    """
    
    @staticmethod
    def analyze_s_curve(yearly_data):
        """
        Realiza un an√°lisis completo de la curva en S con c√°lculos matem√°ticos.
        Versi√≥n mejorada con validaci√≥n de datos suficientes.
        
        Args:
            yearly_data: Diccionario con conteo por a√±o {a√±o: conteo}
            
        Returns:
            DataFrame con los datos analizados, figura, info de ajuste y par√°metros
        """
        if not yearly_data:
            st.error("No hay datos para analizar")
            return None, None, None, None
        
        # Verificar que hay suficientes datos
        if len(yearly_data) < 3:
            st.warning(f"‚ö†Ô∏è Solo hay {len(yearly_data)} a√±os de datos. Se necesitan al menos 3 a√±os para un an√°lisis completo.")
            # Crear DataFrame b√°sico sin an√°lisis avanzado
            df = pd.DataFrame({
                'A√±o': list(yearly_data.keys()),
                'Cantidad': list(yearly_data.values())
            })
            df['Acumulado'] = df['Cantidad'].cumsum()
            
            # Crear gr√°fico simple
            fig = px.line(
                df, x='A√±o', y='Acumulado',
                title='Datos Acumulados por A√±o (An√°lisis B√°sico)',
                markers=True
            )
            fig.update_layout(
                plot_bgcolor='white',
                xaxis=dict(showgrid=True, gridcolor='lightgray'),
                yaxis=dict(showgrid=True, gridcolor='lightgray')
            )
            
            # Info b√°sica
            basic_info = {
                'total_publications': sum(yearly_data.values()),
                'years_span': len(yearly_data),
                'avg_per_year': sum(yearly_data.values()) / len(yearly_data),
                'note': 'Datos insuficientes para an√°lisis completo de curva S'
            }
            
            return df, fig, basic_info, None
        
        # Crear DataFrame base (solo si hay suficientes datos)
        df = pd.DataFrame({
            'A√±o': list(yearly_data.keys()),
            'Cantidad': list(yearly_data.values())
        })
        
        # Calcular acumulado
        df['Acumulado'] = df['Cantidad'].cumsum()
        
        # Establecer a√±o como √≠ndice para c√°lculos
        df_analysis = df.copy()
        df_analysis.set_index('A√±o', inplace=True)
        
        # Calcular la tasa de crecimiento anual
        df_analysis['TasaCrecimiento'] = df_analysis['Acumulado'].pct_change() * 100
        
        # Calcular segunda derivada SOLO si hay suficientes datos
        if len(df_analysis) >= 3:
            try:
                df_analysis['SegundaDerivada'] = np.gradient(np.gradient(df_analysis['Acumulado']))
            except ValueError as e:
                st.warning(f"‚ö†Ô∏è No se pudo calcular la segunda derivada: {str(e)}")
                df_analysis['SegundaDerivada'] = 0
        else:
            df_analysis['SegundaDerivada'] = 0
        
        # Encontrar los a√±os de puntos de inflexi√≥n exactos
        try:
            if len(df_analysis) >= 3 and 'SegundaDerivada' in df_analysis.columns:
                puntos_inflexion_exacto = df_analysis[df_analysis['SegundaDerivada'] == 0].index.tolist()
                if not puntos_inflexion_exacto and len(df_analysis) > 0:
                    # Si no hay puntos exactos con segunda derivada = 0, encontrar el m√°s cercano
                    punto_cercano_idx = np.abs(df_analysis['SegundaDerivada']).idxmin()
                    puntos_inflexion_exacto = [punto_cercano_idx]
            else:
                puntos_inflexion_exacto = []
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Error calculando puntos de inflexi√≥n: {str(e)}")
            puntos_inflexion_exacto = []
        
        # Preparar datos para el ajuste
        x_data = np.array(df_analysis.index)
        y_data = np.array(df_analysis['Acumulado'])
        
        # Ajustar la curva sigmoidal a los datos SOLO si hay suficientes puntos
        if len(x_data) >= 4:  # M√≠nimo 4 puntos para ajuste sigmoidal
            try:
                # Usar los mismos valores iniciales y par√°metros 
                popt, pcov = curve_fit(
                    sigmoid, 
                    x_data, 
                    y_data, 
                    p0=[max(df_analysis['Acumulado']), np.median(df_analysis.index), 0.1], 
                    maxfev=5000
                )
                
                # Calcular los puntos de la curva ajustada
                curva_ajustada = sigmoid(x_data, *popt)
                df_analysis['Ajustada'] = curva_ajustada
                
                # Crear una tabla con datos relevantes
                df_parametros = pd.DataFrame({
                    'Par√°metro': ['L', 'x0', 'k'],
                    'Valor ajustado': popt,
                    'Error est√°ndar': np.sqrt(np.diag(pcov)),
                    'Valor T': popt/np.sqrt(np.diag(pcov)),
                    'Validaci√≥n': ['V√°lido' if abs(valor_t) > 2 else 'No v√°lido' 
                                for valor_t in popt/np.sqrt(np.diag(pcov))]
                })
                
                # C√°lculo de R¬≤
                r_squared = 1 - np.sum((y_data - curva_ajustada)**2) / np.sum((y_data - np.mean(y_data))**2)
                
                # Determinar la fase actual
                if len(df_analysis) >= 3:
                    ultima_derivada = df_analysis['SegundaDerivada'].iloc[-3:].mean() if len(df_analysis) >= 3 else 0
                else:
                    ultima_derivada = 0
                
                if ultima_derivada > 0:
                    fase = "Fase inicial (crecimiento acelerado)"
                    descripcion = "La tecnolog√≠a est√° en su fase temprana con crecimiento acelerado."
                elif ultima_derivada < 0:
                    fase = "Fase de madurez (crecimiento desacelerado)"
                    descripcion = "La tecnolog√≠a est√° madurando, el crecimiento se est√° desacelerando."
                else:
                    fase = "Punto de inflexi√≥n"
                    descripcion = "La tecnolog√≠a est√° en el punto de inflexi√≥n entre el crecimiento acelerado y desacelerado."
                
                # Crear figura de Plotly con la curva acumulada y el ajuste
                fig = px.line(
                    df_analysis, x=df_analysis.index, y=['Acumulado', 'Ajustada'],
                    labels={'value': 'Cantidad Acumulada', 'variable': 'Tipo de Curva', 'A√±o': 'A√±o'},
                    title='Curva S - Acumulado por A√±o',
                    color_discrete_map={'Acumulado': 'blue', 'Ajustada': 'red'},
                    markers=True
                )
                
                # A√±adir puntos de inflexi√≥n si existen
                for punto in puntos_inflexion_exacto:
                    fig.add_trace(
                        go.Scatter(
                            x=[punto],
                            y=[df_analysis.loc[punto, 'Acumulado']],
                            mode='markers',
                            name=f'Punto de inflexi√≥n ({punto})',
                            marker=dict(color='red', size=15, symbol='star')
                        )
                    )
                
                # Informaci√≥n de ajuste
                ajuste_info = {
                    'R2': r_squared,
                    'L': popt[0],
                    'x0': popt[1],
                    'k': popt[2],
                    'Fase': fase,
                    'Descripci√≥n': descripcion,
                    'Puntos_inflexion': puntos_inflexion_exacto
                }
                
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Error en el ajuste de curva sigmoidal: {str(e)}")
                # Crear gr√°fico simple sin ajuste
                fig = px.line(
                    df_analysis, x=df_analysis.index, y='Acumulado',
                    title='Datos Acumulados por A√±o (Sin Ajuste)',
                    markers=True
                )
                
                # Info b√°sica sin ajuste
                ajuste_info = {
                    'total_publications': sum(yearly_data.values()),
                    'years_span': len(yearly_data),
                    'avg_per_year': sum(yearly_data.values()) / len(yearly_data),
                    'note': 'No se pudo realizar ajuste sigmoidal'
                }
                df_parametros = None
        else:
            # No hay suficientes datos para ajuste sigmoidal
            st.warning(f"‚ö†Ô∏è Solo hay {len(x_data)} puntos de datos. Se necesitan al menos 4 para ajuste sigmoidal.")
            
            # Crear gr√°fico simple
            fig = px.line(
                df_analysis, x=df_analysis.index, y='Acumulado',
                title='Datos Acumulados por A√±o (An√°lisis B√°sico)',
                markers=True
            )
            
            # Info b√°sica
            ajuste_info = {
                'total_publications': sum(yearly_data.values()),
                'years_span': len(yearly_data),
                'avg_per_year': sum(yearly_data.values()) / len(yearly_data),
                'note': 'Datos insuficientes para ajuste sigmoidal'
            }
            df_parametros = None
        
        # Mejorar aspecto visual del gr√°fico
        fig.update_layout(
            width=600,
            height=600,
            legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='center', x=0.5),
            plot_bgcolor='white',
            xaxis=dict(showgrid=True, gridcolor='lightgray'),
            yaxis=dict(showgrid=True, gridcolor='lightgray')
        )
        
        # Restaurar el √≠ndice para el DataFrame original
        df_analysis = df_analysis.reset_index()
        
        return df_analysis, fig, ajuste_info, df_parametros
    
    
    @staticmethod
    def display_data_table(yearly_data, title="Datos por A√±o"):
        """
        Muestra una tabla con los datos por a√±o.
        
        Args:
            yearly_data: Diccionario {a√±o: conteo}
            title: T√≠tulo de la tabla
            
        Returns:
            DataFrame con los datos
        """
        if not yearly_data:
            st.error("No hay datos para mostrar")
            return None
        
        df = pd.DataFrame({
            'A√±o': list(yearly_data.keys()),
            'Cantidad': list(yearly_data.values())
        })
        
        # Calcular acumulado
        df['Acumulado'] = df['Cantidad'].cumsum()
        
        # Formatear a√±os como enteros sin comas
        df['A√±o'] = df['A√±o'].astype(int)
        
        # Mostrar tabla
        st.write(f"### üìã {title}")
        
        # Usar el componente nativo de Streamlit para tablas con estilo
        st.dataframe(
            df,
            use_container_width=True,
            hide_index=True,
            column_config={
                "A√±o": st.column_config.NumberColumn(format="%d"),
                "Cantidad": st.column_config.NumberColumn(format="%d"),
                "Acumulado": st.column_config.NumberColumn(format="%d")
            }
        )
        
        return df
    
    @staticmethod
    def display_s_curve_analysis(analysis_df, analysis_fig, ajuste_info, parametros, title="An√°lisis de Curva en S"):
        """
        Muestra el an√°lisis completo de la curva en S.
        
        Args:
            analysis_df: DataFrame con los datos analizados
            analysis_fig: Figura de Plotly
            ajuste_info: Informaci√≥n del ajuste
            parametros: DataFrame con los par√°metros del modelo
            title: T√≠tulo del an√°lisis
        """
        st.write(f"### üìä {title}")
        
        # Mostrar gr√°fico de an√°lisis
        if analysis_fig:
            st.plotly_chart(analysis_fig, use_container_width=True)
            
            # Mostrar informaci√≥n del ajuste
            if ajuste_info:
                st.write("#### Par√°metros del Modelo Ajustado")
                
                # Crear columnas para mostrar m√©tricas
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("R¬≤ del ajuste", f"{ajuste_info['R2']:.4f}")
                with col2:
                    st.metric("Punto de inflexi√≥n (x0)", f"{ajuste_info['x0']:.1f}")
                with col3:
                    st.metric("M√°ximo te√≥rico (L)", f"{ajuste_info['L']:.1f}")
                
                # Mostrar par√°metros del modelo
                if parametros is not None:
                    st.write("#### Par√°metros del modelo sigmoidal")
                    
                    # Usar st.dataframe con estilo
                    st.dataframe(
                        parametros,
                        use_container_width=True,
                        hide_index=True,
                        column_config={
                            "Valor ajustado": st.column_config.NumberColumn("Valor ajustado", format="%.4f"),
                            "Error est√°ndar": st.column_config.NumberColumn("Error est√°ndar", format="%.4f"),
                            "Valor T": st.column_config.NumberColumn("Valor T", format="%.4f")
                        }
                    )
                
                # Mostrar fase actual
                st.info(f"**Fase actual de la tecnolog√≠a**: {ajuste_info['Fase']}")
                st.write(ajuste_info['Descripci√≥n'])
    
    @staticmethod
    def export_data(df, filename_prefix, query):
        """
        Genera un bot√≥n para exportar los datos a CSV.
        
        Args:
            df: DataFrame con los datos
            filename_prefix: Prefijo para el nombre del archivo
            query: Consulta utilizada
        """
        if df is not None:
            st.write("### üì• Exportar Datos")
            
            # Bot√≥n para descargar CSV
            csv = df.to_csv(index=False)
            query_term_clean = re.sub(r'[^\w\s]', '', query[:30])
            filename = f"{filename_prefix}_{query_term_clean}_{datetime.now().strftime('%Y%m%d')}.csv"
            
            st.download_button(
                label=f"üì• Descargar datos {filename_prefix} (CSV)",
                data=csv,
                file_name=filename,
                mime="text/csv",
                key=f"download_csv_{filename_prefix}_{int(time.time())}"  # ‚Üê KEY √öNICO AGREGADO
            )

class OptimizedGooglePatentsAnalyzer:
    """
    Analizador optimizado de Google Patents que minimiza el consumo de tokens
    mediante estrategias inteligentes de b√∫squeda.
    """
    
    def __init__(self, api_key=None):
        self.api_key = api_key
        self.base_url = "https://serpapi.com/search"
        self.patents_by_year = {}
        self.cache = {}  # Cache para evitar b√∫squedas duplicadas
        
    def analyze_patents_optimized(self, query, start_year=None, end_year=None, max_tokens=50):
        """
        An√°lisis optimizado que minimiza el consumo de tokens usando m√∫ltiples estrategias.
        
        Args:
            query: Query de b√∫squeda original
            start_year: A√±o inicial (default: current_year - 25)
            end_year: A√±o final (default: current_year)
            max_tokens: M√°ximo n√∫mero de requests permitidos
            
        Returns:
            dict: Patentes por a√±o {a√±o: cantidad}
        """
        current_year = datetime.now().year
        if not start_year:
            start_year = current_year - 25
        if not end_year:
            end_year = current_year
            
        st.info(f"üéØ **Estrategia Optimizada**: M√°ximo {max_tokens} requests para {end_year - start_year + 1} a√±os")
        
        # PASO 1: Validar que la query funciona
        simplified_query = self._create_ultra_simple_query(query)
        if not self._validate_query_works(simplified_query):
            return None
            
        # PASO 2: Estrategia h√≠brida basada en rangos de a√±os
        patents_by_year = {}
        tokens_used = 0
        
        # Definir estrategias por √©poca
        strategies = [
            {
                'name': '√âpoca Antigua', 
                'range': (start_year, min(1999, end_year)),
                'strategy': 'bulk_search',  # B√∫squeda masiva + procesamiento
                'batch_size': 20  # a√±os por b√∫squeda
            },
            {
                'name': '√âpoca Moderna Temprana',
                'range': (max(2000, start_year), min(2009, end_year)),
                'strategy': 'decade_search',  # Por d√©cadas
                'batch_size': 10
            },
            {
                'name': '√âpoca Reciente',
                'range': (max(2010, start_year), end_year),
                'strategy': 'smart_sampling',  # Muestreo inteligente
                'batch_size': 5
            }
        ]
        
        for strategy_info in strategies:
            if tokens_used >= max_tokens:
                st.warning(f"‚ö†Ô∏è L√≠mite de tokens alcanzado ({max_tokens}). Deteniendo b√∫squeda.")
                break
                
            range_start, range_end = strategy_info['range']
            if range_start > range_end:
                continue
                
            st.write(f"### üìä {strategy_info['name']} ({range_start}-{range_end})")
            
            strategy_result, tokens_consumed = self._execute_strategy(
                simplified_query, 
                range_start, 
                range_end, 
                strategy_info,
                max_tokens - tokens_used
            )
            
            if strategy_result:
                patents_by_year.update(strategy_result)
                tokens_used += tokens_consumed
                
            st.caption(f"‚úÖ Tokens usados en esta √©poca: {tokens_consumed} | Total: {tokens_used}/{max_tokens}")
        
        # PASO 3: Completar a√±os faltantes con interpolaci√≥n/extrapolaci√≥n
        if patents_by_year:
            patents_by_year = self._fill_missing_years(patents_by_year, start_year, end_year)
            
        # PASO 4: Mostrar resumen de optimizaci√≥n
        self._show_optimization_summary(patents_by_year, tokens_used, max_tokens)
        
        return patents_by_year
    
    def _validate_query_works(self, query):
        """Valida que la query funciona con una b√∫squeda simple."""
        st.text("üîç Validando query...")
        
        try:
            params = {
                "engine": "google_patents",
                "q": query,
                "api_key": self.api_key,
                "num": 10
            }
            
            response = requests.get(self.base_url, params=params, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                if "error" not in data:
                    total_results = data.get("search_information", {}).get("total_results", 0)
                    total_results = int(str(total_results).replace(",", "")) if total_results else 0
                    
                    if total_results > 0:
                        st.success(f"‚úÖ Query v√°lida: {total_results:,} resultados totales")
                        return True
                    else:
                        st.warning(f"‚ö†Ô∏è Query muy espec√≠fica: 0 resultados. Usando query ultra-simple.")
                        return False
                else:
                    st.error(f"‚ùå Error en query: {data.get('error', 'Unknown')}")
                    return False
            else:
                st.error(f"‚ùå Error HTTP: {response.status_code}")
                return False
                
        except Exception as e:
            st.error(f"‚ùå Error validando query: {str(e)}")
            return False
    
    def _execute_strategy(self, query, start_year, end_year, strategy_info, max_tokens):
        """Ejecuta una estrategia espec√≠fica de b√∫squeda."""
        strategy = strategy_info['strategy']
        
        if strategy == 'bulk_search':
            return self._bulk_search_strategy(query, start_year, end_year, max_tokens)
        elif strategy == 'decade_search':
            return self._decade_search_strategy(query, start_year, end_year, max_tokens)
        elif strategy == 'smart_sampling':
            return self._smart_sampling_strategy(query, start_year, end_year, max_tokens)
        else:
            return {}, 0
    
    def _bulk_search_strategy(self, query, start_year, end_year, max_tokens):
        """
        Estrategia de b√∫squeda masiva: Obtiene muchos resultados de una vez
        y extrae los a√±os de los metadatos.
        """
        patents_by_year = {}
        tokens_used = 0
        
        if tokens_used >= max_tokens:
            return patents_by_year, tokens_used
        
        try:
            # B√∫squeda amplia sin filtros de fecha
            params = {
                "engine": "google_patents",
                "q": f"{query} after:{start_year-1}-12-31 before:{end_year+1}-01-01",
                "api_key": self.api_key,
                "num": 100,  # Obtener m√°s resultados por b√∫squeda
                "start": 0
            }
            
            st.text(f"üîÑ B√∫squeda masiva {start_year}-{end_year}...")
            
            # Hacer m√∫ltiples p√°ginas si es necesario
            all_patents = []
            max_pages = min(5, max_tokens)  # L√≠mite de p√°ginas
            
            for page in range(max_pages):
                if tokens_used >= max_tokens:
                    break
                    
                params["start"] = page * 100
                response = requests.get(self.base_url, params=params, timeout=30)
                tokens_used += 1
                
                if response.status_code == 200:
                    data = response.json()
                    if "error" not in data and "organic_results" in data:
                        patents = data["organic_results"]
                        if not patents:  # No m√°s resultados
                            break
                        all_patents.extend(patents)
                    else:
                        break
                else:
                    break
                    
                time.sleep(0.3)  # Rate limiting
            
            # Procesar resultados para extraer a√±os
            if all_patents:
                for patent in all_patents:
                    year = self._extract_year_from_patent(patent)
                    if year and start_year <= year <= end_year:
                        patents_by_year[year] = patents_by_year.get(year, 0) + 1
                
                st.success(f"‚úÖ Procesados {len(all_patents)} patentes, encontrados {sum(patents_by_year.values())} en rango")
            
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Error en b√∫squeda masiva: {str(e)}")
        
        return patents_by_year, tokens_used
    
    def _decade_search_strategy(self, query, start_year, end_year, max_tokens):
        """Estrategia por d√©cadas: Busca por rangos de 10 a√±os."""
        patents_by_year = {}
        tokens_used = 0
        
        # Crear rangos de d√©cadas
        decade_ranges = []
        current = start_year
        while current <= end_year:
            decade_end = min(current + 9, end_year)
            decade_ranges.append((current, decade_end))
            current += 10
        
        for decade_start, decade_end in decade_ranges:
            if tokens_used >= max_tokens:
                break
                
            try:
                params = {
                    "engine": "google_patents",
                    "q": f"{query} after:{decade_start-1}-12-31 before:{decade_end+1}-01-01",
                    "api_key": self.api_key,
                    "num": 50
                }
                
                st.text(f"üîÑ D√©cada {decade_start}-{decade_end}...")
                
                response = requests.get(self.base_url, params=params, timeout=30)
                tokens_used += 1
                
                if response.status_code == 200:
                    data = response.json()
                    if "error" not in data:
                        total_results = data.get("search_information", {}).get("total_results", 0)
                        total_results = int(str(total_results).replace(",", "")) if total_results else 0
                        
                        # Distribuir uniformemente los resultados en la d√©cada
                        if total_results > 0:
                            years_in_decade = decade_end - decade_start + 1
                            avg_per_year = total_results // years_in_decade
                            remainder = total_results % years_in_decade
                            
                            for i, year in enumerate(range(decade_start, decade_end + 1)):
                                patents_by_year[year] = avg_per_year + (1 if i < remainder else 0)
                
                time.sleep(0.3)
                
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Error en d√©cada {decade_start}-{decade_end}: {str(e)}")
        
        return patents_by_year, tokens_used
    
    def _smart_sampling_strategy(self, query, start_year, end_year, max_tokens):
        """Estrategia de muestreo inteligente: Busca a√±os clave y extrapola."""
        patents_by_year = {}
        tokens_used = 0
        
        # Seleccionar a√±os clave para muestrear
        total_years = end_year - start_year + 1
        if total_years <= max_tokens:
            # Si hay suficientes tokens, buscar a√±o por a√±o
            sample_years = list(range(start_year, end_year + 1))
        else:
            # Muestrear a√±os estrat√©gicamente
            sample_size = min(max_tokens, total_years // 2)
            sample_years = self._select_strategic_years(start_year, end_year, sample_size)
        
        st.text(f"üéØ Muestreando {len(sample_years)} a√±os clave de {total_years} totales")
        
        # Buscar a√±os seleccionados
        for year in sample_years:
            if tokens_used >= max_tokens:
                break
                
            try:
                params = {
                    "engine": "google_patents",
                    "q": f"{query} after:{year-1}-12-31 before:{year+1}-01-01",
                    "api_key": self.api_key,
                    "num": 10
                }
                
                response = requests.get(self.base_url, params=params, timeout=30)
                tokens_used += 1
                
                if response.status_code == 200:
                    data = response.json()
                    if "error" not in data:
                        total_results = data.get("search_information", {}).get("total_results", 0)
                        total_results = int(str(total_results).replace(",", "")) if total_results else 0
                        patents_by_year[year] = total_results
                
                time.sleep(0.2)
                
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Error en a√±o {year}: {str(e)}")
        
        return patents_by_year, tokens_used
    
    def _select_strategic_years(self, start_year, end_year, sample_size):
        """Selecciona a√±os estrat√©gicos para muestrear."""
        years = list(range(start_year, end_year + 1))
        
        if sample_size >= len(years):
            return years
        
        # Estrategia: Incluir siempre primer a√±o, √∫ltimo a√±o, y distribuir el resto
        strategic_years = [start_year, end_year]
        
        if sample_size > 2:
            # A√±adir a√±os intermedios uniformemente distribuidos
            remaining_sample = sample_size - 2
            step = max(1, (end_year - start_year - 1) // (remaining_sample + 1))
            
            for i in range(1, remaining_sample + 1):
                year = start_year + i * step
                if year < end_year and year not in strategic_years:
                    strategic_years.append(year)
        
        return sorted(strategic_years)
    
    def _fill_missing_years(self, patents_by_year, start_year, end_year):
        """Completa a√±os faltantes usando interpolaci√≥n."""
        if not patents_by_year:
            return patents_by_year
        
        # Crear lista completa de a√±os
        all_years = list(range(start_year, end_year + 1))
        filled_data = {}
        
        for year in all_years:
            if year in patents_by_year:
                filled_data[year] = patents_by_year[year]
            else:
                # Interpolaci√≥n simple entre a√±os conocidos
                filled_data[year] = self._interpolate_value(year, patents_by_year)
        
        return filled_data
    
    def _interpolate_value(self, target_year, known_data):
        """Interpola valor para un a√±o faltante."""
        if not known_data:
            return 0
        
        known_years = sorted(known_data.keys())
        
        # Si el a√±o objetivo est√° fuera del rango, usar extrapolaci√≥n simple
        if target_year < min(known_years):
            return max(0, known_data[min(known_years)] // 2)  # Mitad del valor m√°s temprano
        elif target_year > max(known_years):
            return known_data[max(known_years)]  # Mismo valor que el m√°s reciente
        
        # Interpolaci√≥n lineal entre dos puntos conocidos
        for i in range(len(known_years) - 1):
            year1, year2 = known_years[i], known_years[i + 1]
            if year1 <= target_year <= year2:
                value1, value2 = known_data[year1], known_data[year2]
                ratio = (target_year - year1) / (year2 - year1)
                return int(value1 + ratio * (value2 - value1))
        
        return 0
    
    def _extract_year_from_patent(self, patent_data):
        """Extrae el a√±o de los metadatos de una patente."""
        # Intentar diferentes campos donde puede estar la fecha
        date_fields = [
            'publication_date', 
            'patent_date', 
            'filing_date',
            'priority_date'
        ]
        
        for field in date_fields:
            if field in patent_data:
                year = self._extract_year_from_date_string(patent_data[field])
                if year:
                    return year
        
        # Buscar en t√≠tulo o snippet
        text_to_search = f"{patent_data.get('title', '')} {patent_data.get('snippet', '')}"
        return self._extract_year_from_text(text_to_search)
    
    def _extract_year_from_date_string(self, date_str):
        """Extrae a√±o de string de fecha."""
        if not date_str:
            return None
        
        # Buscar patr√≥n de a√±o (4 d√≠gitos)
        import re
        match = re.search(r'\b(19|20)\d{2}\b', str(date_str))
        if match:
            year = int(match.group())
            current_year = datetime.now().year
            if 1900 <= year <= current_year:
                return year
        return None
    
    def _extract_year_from_text(self, text):
        """Extrae a√±o de texto libre."""
        if not text:
            return None
        
        import re
        current_year = datetime.now().year
        years = re.findall(r'\b(19|20)\d{2}\b', text)
        
        if years:
            valid_years = [int(y) for y in years if 1900 <= int(y) <= current_year]
            if valid_years:
                return max(valid_years)  # Retornar el a√±o m√°s reciente
        return None
    
    def _create_ultra_simple_query(self, original_query):
        """Crea una query ultra-simple que tenga m√°s probabilidad de funcionar."""
        # Extraer conceptos clave
        import re
        
        # Buscar t√©rminos entre comillas
        quoted_terms = re.findall(r'"([^"]+)"', original_query)
        
        if quoted_terms:
            # Usar solo el primer t√©rmino y simplificar
            main_term = quoted_terms[0].strip()
            # Tomar solo la primera palabra del t√©rmino principal
            words = main_term.split()
            if words:
                return f'"{words[0]}"'
        
        # Si no hay t√©rminos entre comillas, extraer palabras clave
        clean_query = re.sub(r'[()><=]', ' ', original_query)
        clean_query = re.sub(r'\b(AND|OR|NOT|TITLE|ABS|KEY)\b', ' ', clean_query)
        words = re.findall(r'\b[a-zA-Z]{4,}\b', clean_query)
        
        if words:
            return f'"{words[0]}"'
        
        # Fallback absoluto
        return "technology"
    
    def _show_optimization_summary(self, patents_by_year, tokens_used, max_tokens):
        """Muestra resumen de la optimizaci√≥n."""
        if not patents_by_year:
            st.error("‚ùå No se obtuvieron datos de patentes")
            return
        
        total_patents = sum(patents_by_year.values())
        years_covered = len(patents_by_year)
        
        st.success(f"üéØ **Optimizaci√≥n Exitosa**")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Tokens Usados", f"{tokens_used}/{max_tokens}")
        with col2:
            st.metric("Total Patentes", f"{total_patents:,}")
        with col3:
            st.metric("A√±os Cubiertos", years_covered)
        with col4:
            efficiency = total_patents / tokens_used if tokens_used > 0 else 0
            st.metric("Eficiencia", f"{efficiency:.1f} patentes/token")
        
        # Mostrar ahorro de tokens
        naive_tokens = years_covered  # Un token por a√±o
        tokens_saved = naive_tokens - tokens_used
        if tokens_saved > 0:
            st.info(f"üí∞ **Ahorro**: {tokens_saved} tokens ({tokens_saved/naive_tokens*100:.1f}% menos que b√∫squeda a√±o por a√±o)")


# Funci√≥n para integrar en el c√≥digo existente
def integrate_optimized_patents_search():
    """
    Funci√≥n para reemplazar la b√∫squeda de patentes existente.
    Usar esta funci√≥n en lugar de GooglePatentsAnalyzer.search_patents()
    """
    
    def run_optimized_patents_analysis(scopus_query, start_year, end_year, serp_api_key, max_tokens=30):
        """
        Ejecuta an√°lisis optimizado de patentes.
        
        Args:
            scopus_query: Query original de Scopus
            start_year: A√±o inicial
            end_year: A√±o final
            serp_api_key: API key de SerpAPI
            max_tokens: M√°ximo n√∫mero de requests (default: 30)
            
        Returns:
            dict: Patentes por a√±o
        """
        
        st.write("### üöÄ An√°lisis Optimizado de Patentes")
        
        # Configuraci√≥n de optimizaci√≥n
        with st.expander("‚öôÔ∏è Configuraci√≥n de Optimizaci√≥n", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                max_tokens = st.slider(
                    "M√°ximo tokens a usar",
                    min_value=10,
                    max_value=100,
                    value=max_tokens,
                    help="Cada token = 1 request a SerpAPI"
                )
            
            with col2:
                years_span = end_year - start_year + 1
                naive_cost = years_span
                st.metric("Costo b√∫squeda naive", f"{naive_cost} tokens")
                st.metric("Costo optimizado", f"‚â§{max_tokens} tokens")
                
                if max_tokens < naive_cost:
                    savings = naive_cost - max_tokens
                    st.success(f"üí∞ Ahorro: {savings} tokens ({savings/naive_cost*100:.1f}%)")
        
        # Ejecutar an√°lisis optimizado
        analyzer = OptimizedGooglePatentsAnalyzer(serp_api_key)
        patents_by_year = analyzer.analyze_patents_optimized(
            scopus_query, 
            start_year, 
            end_year, 
            max_tokens
        )
        
        return patents_by_year
    
    return run_optimized_patents_analysis    

def run_s_curve_analysis():
    """
    Ejecuta el an√°lisis de curva en S para publicaciones acad√©micas y patentes.
    """
    st.title("üìà An√°lisis de Curvas en S: Papers y Patentes")
    
    st.write("""
    Esta herramienta te permite analizar tendencias tecnol√≥gicas a lo largo del tiempo 
    utilizando datos de publicaciones acad√©micas (papers) y patentes. El an√°lisis de curvas en S 
    te ayuda a entender la fase de madurez en la que se encuentra una tecnolog√≠a.
    """)
    
    # Configuraci√≥n de APIs en el sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è Configuraci√≥n")
        
        api_key_input = st.text_input(
            "API Key de Scopus",
            value=st.session_state.get('scopus_api_key', ''),
            type="password",
            help="Ingresa tu API key de Scopus/Elsevier"
        )
        
        use_default_key = st.checkbox(
            "Usar API key de ejemplo", 
            value=True, 
            help="Usa una API key de ejemplo para probar la aplicaci√≥n"
        )
        
        if use_default_key:
            api_key = "113f57bcfb9e922c5a33ec02233ee24d"
        else:
            api_key = api_key_input
        
        st.session_state.scopus_api_key = api_key
        
        # Verificar SerpAPI para patentes
        serp_api_available = bool(st.session_state.get('serp_api_key'))
        if serp_api_available:
            st.success("‚úÖ SerpAPI configurado para patentes")
        else:
            st.warning("‚ö†Ô∏è Configura SerpAPI para buscar patentes")
        
        # Opciones para tipos de datos
        st.subheader("Tipos de datos")
        analyze_papers = st.checkbox("Analizar papers", value=True)
        analyze_patents = st.checkbox("Analizar patentes", value=serp_api_available)
    
    # PESTA√ëAS PRINCIPALES
    tab1, tab2 = st.tabs(["üîç An√°lisis Autom√°tico", "üì§ Carga Manual (Excel)"])
    
    # =================================================================
    # PESTA√ëA 1: AN√ÅLISIS AUTOM√ÅTICO
    # =================================================================
    with tab1:
        st.header("üîç An√°lisis Autom√°tico")
        st.write("Busca autom√°ticamente papers en Scopus y patentes en Google Patents")
        
        # Pesta√±as para diferentes m√©todos de construcci√≥n de consulta
        query_tab1, query_tab2 = st.tabs(["Generador de Ecuaciones", "Ecuaci√≥n Manual"])
        
        with query_tab1:
            # Utilizar el constructor de ecuaciones Scopus
            scopus_query = scopus_equation_interface()
        
        with query_tab2:
            # Entrada manual de ecuaci√≥n
            manual_query = st.text_area(
                "Ecuaci√≥n de b√∫squeda",
                placeholder='Ej: TITLE("Plantain" OR "banana" OR "musa") AND TITLE("flour" OR "starch")',
                height=100,
                key="manual_query_input_auto"
            )
            scopus_query = manual_query if manual_query else ""
        
        # Configuraci√≥n de b√∫squeda
        with st.expander("‚öôÔ∏è Configuraci√≥n de B√∫squeda", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**Papers (Scopus):**")
                max_results = st.slider(
                    "N√∫mero m√°ximo de resultados",
                    min_value=500,
                    max_value=10000,
                    value=2000,
                    step=100,
                    help="Mayor n√∫mero = an√°lisis m√°s completo, pero toma m√°s tiempo"
                )
            
            with col2:
                st.write("**Patentes (Google Patents):**")
                col2a, col2b = st.columns(2)
                
                with col2a:
                    patents_start_year = st.number_input(
                        "A√±o inicial", 
                        min_value=1950, 
                        max_value=datetime.now().year-1,
                        value=datetime.now().year - 20,
                        key="patents_start_year_main"
                    )
                    # Guardar en session_state
                    st.session_state['patents_start_year_config'] = patents_start_year
                
                with col2b:
                    patents_end_year = st.number_input(
                        "A√±o final", 
                        min_value=patents_start_year,
                        max_value=datetime.now().year,
                        value=datetime.now().year,
                        key="patents_end_year_main"
                    )
                    # Guardar en session_state
                    st.session_state['patents_end_year_config'] = patents_end_year
                
                years_span = patents_end_year - patents_start_year + 1
                st.caption(f"üì° {years_span} requests a SerpAPI (uno por a√±o)")
        
        # BOT√ìN PRINCIPAL DE AN√ÅLISIS
        if st.button("üîç Analizar Tecnolog√≠a", type="primary", use_container_width=True):
            if not scopus_query:
                st.error("Por favor, ingresa una ecuaci√≥n de b√∫squeda v√°lida")
                return
            
            if not analyze_papers and not analyze_patents:
                st.warning("Selecciona al menos un tipo de datos para analizar (papers o patentes).")
                return
            
            # Variables para almacenar resultados
            papers_by_year = None
            patents_by_year = None
            papers_analysis = None
            patents_analysis = None
            
            # =============================================================
            # 1. AN√ÅLISIS DE PAPERS
            # =============================================================
            if analyze_papers:
                st.write("## üìö An√°lisis de Publicaciones Acad√©micas (Papers)")
                
                if not api_key:
                    st.error("‚ö†Ô∏è Se requiere API Key de Scopus para analizar papers")
                else:
                    with st.spinner("üîÑ Analizando publicaciones acad√©micas..."):
                        try:
                            # Instanciar el analizador de papers
                            papers_analyzer = ScopusPublicationsAnalyzer(api_key)
                            
                            # Buscar papers
                            papers_results = papers_analyzer.search_publications(
                                scopus_query,
                                max_results=max_results
                            )
                            
                            # Verificar si se obtuvieron resultados
                            if papers_results:
                                # Categorizar por a√±o
                                papers_by_year = papers_analyzer.categorize_by_year(papers_results)
                                
                                # Verificar si hay datos disponibles
                                if papers_by_year:
                                    # Mostrar tabla de papers por a√±o
                                    df_papers = TechnologyAnalyzer.display_data_table(
                                        papers_by_year, 
                                        title="Tabla de Papers por A√±o"
                                    )
                                    
                                    # Realizar an√°lisis de curva en S
                                    analysis_df, analysis_fig, ajuste_info, parametros = TechnologyAnalyzer.analyze_s_curve(papers_by_year)
                                    
                                    # Mostrar an√°lisis de curva en S
                                    TechnologyAnalyzer.display_s_curve_analysis(
                                        analysis_df, 
                                        analysis_fig, 
                                        ajuste_info, 
                                        parametros,
                                        title="An√°lisis de Curva en S - Papers"
                                    )
                                    
                                    # Guardar para comparaci√≥n posterior
                                    papers_analysis = {
                                        'df': analysis_df if analysis_df is not None else df_papers,
                                        'metrics': ajuste_info
                                    }
                                    
                                    # Exportar datos
                                    TechnologyAnalyzer.export_data(
                                        analysis_df if analysis_df is not None else df_papers,
                                        "papers",
                                        scopus_query
                                    )
                                else:
                                    st.warning("No se pudieron categorizar los papers por a√±o.")
                            else:
                                st.error("No se pudieron obtener resultados de papers. Verifica tu API key y la ecuaci√≥n de b√∫squeda.")
                        
                        except Exception as e:
                            st.error(f"Error en el an√°lisis de papers: {str(e)}")
                            import traceback
                            st.code(traceback.format_exc())
            
            # =============================================================
            # 2. AN√ÅLISIS DE PATENTES - OPTIMIZADO
            # =============================================================
            if analyze_patents:
                st.write("## üìë An√°lisis de Patentes (Optimizado)")
                
                if not st.session_state.get('serp_api_key'):
                    st.error("‚ö†Ô∏è Se requiere SerpAPI Key para analizar patentes. Config√∫rala en el panel lateral.")
                    patents_by_year = None
                    patents_analysis = None
                else:
                    # NUEVA CONFIGURACI√ìN DE OPTIMIZACI√ìN
                    with st.expander("üéØ Configuraci√≥n de Optimizaci√≥n", expanded=True):
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            max_tokens = st.slider(
                                "M√°ximo tokens SerpAPI",
                                min_value=5,
                                max_value=100,
                                value=25,
                                help="Cada token = 1 request. Menos tokens = m√°s optimizaci√≥n."
                            )
                        
                        with col2:
                            patents_start_year = st.session_state.get('patents_start_year_config', datetime.now().year - 15)
                            patents_end_year = st.session_state.get('patents_end_year_config', datetime.now().year)
                            years_span = patents_end_year - patents_start_year + 1
                            naive_cost = years_span
                            
                            st.metric("A√±os a analizar", years_span)
                            st.metric("Costo m√©todo naive", f"{naive_cost} tokens")
                        
                        with col3:
                            potential_savings = max(0, naive_cost - max_tokens)
                            savings_percent = (potential_savings / naive_cost * 100) if naive_cost > 0 else 0
                            
                            st.metric("Costo optimizado", f"‚â§{max_tokens} tokens")
                            if potential_savings > 0:
                                st.metric(
                                    "Ahorro estimado", 
                                    f"{potential_savings} tokens",
                                    delta=f"-{savings_percent:.1f}%"
                                )
                    
                    # EJECUTAR AN√ÅLISIS OPTIMIZADO
                    with st.spinner("üîÑ Ejecutando an√°lisis optimizado de patentes..."):
                        try:
                            # Usar la nueva clase optimizada
                            analyzer = OptimizedGooglePatentsAnalyzer(st.session_state.serp_api_key)
                            
                            patents_by_year = analyzer.analyze_patents_optimized(
                                scopus_query,
                                start_year=patents_start_year,
                                end_year=patents_end_year,
                                max_tokens=max_tokens
                            )
                            
                            # Verificar si se obtuvieron resultados
                            if patents_by_year and sum(patents_by_year.values()) > 0:
                                # Mostrar tabla de patentes por a√±o
                                df_patents = TechnologyAnalyzer.display_data_table(
                                    patents_by_year, 
                                    title="Tabla de Patentes por A√±o (Optimizada)"
                                )
                                
                                # Realizar an√°lisis de curva en S
                                analysis_df, analysis_fig, ajuste_info, parametros = TechnologyAnalyzer.analyze_s_curve(patents_by_year)
                                
                                # Mostrar an√°lisis de curva en S
                                TechnologyAnalyzer.display_s_curve_analysis(
                                    analysis_df, 
                                    analysis_fig, 
                                    ajuste_info, 
                                    parametros,
                                    title="An√°lisis de Curva en S - Patentes (Optimizado)"
                                )
                                
                                # Guardar para comparaci√≥n posterior
                                patents_analysis = {
                                    'df': analysis_df if analysis_df is not None else df_patents,
                                    'metrics': ajuste_info
                                }
                                
                                # Exportar datos
                                TechnologyAnalyzer.export_data(
                                    analysis_df if analysis_df is not None else df_patents,
                                    "patentes_optimizado",
                                    scopus_query
                                )
                                
                                # Mostrar estad√≠sticas de optimizaci√≥n
                                st.success("‚úÖ An√°lisis de patentes completado exitosamente")
                                
                            else:
                                st.warning("‚ö†Ô∏è No se obtuvieron resultados de patentes. Posibles causas:")
                                st.write("""
                                - La consulta es muy espec√≠fica
                                - No existen patentes para esta tecnolog√≠a en el rango de a√±os
                                - Problema con la API de Google Patents
                                """)
                                
                                # Mostrar sugerencias para mejorar resultados
                                with st.expander("üí° Sugerencias para mejorar resultados"):
                                    st.write("""
                                    **Prueba estas estrategias:**
                                    
                                    1. **Simplifica la consulta**: Usa t√©rminos m√°s generales
                                    2. **Ampl√≠a el rango de a√±os**: Incluye a√±os m√°s antiguos
                                    3. **Incrementa el l√≠mite de tokens**: Permite m√°s b√∫squedas
                                    4. **Verifica la tecnolog√≠a**: Algunas tecnolog√≠as tienen pocas patentes
                                    """)
                                
                                patents_by_year = None
                                patents_analysis = None
                            
                        except Exception as e:
                            st.error(f"‚ùå Error en el an√°lisis optimizado de patentes: {str(e)}")
                            
                            # Mostrar informaci√≥n de debug
                            with st.expander("üîß Informaci√≥n de Debug"):
                                st.write("**Query original:**")
                                st.code(scopus_query)
                                
                                st.write("**Error completo:**")
                                import traceback
                                st.code(traceback.format_exc())
                            
                            patents_by_year = None
                            patents_analysis = None

            # 3. A√ëADIR FUNCI√ìN AUXILIAR PARA AN√ÅLISIS R√ÅPIDO DE VIABILIDAD
            def check_patents_viability(query, serp_api_key):
                """
                Funci√≥n auxiliar para verificar r√°pidamente si vale la pena analizar patentes.
                Usa solo 1 token para verificar.
                """
                try:
                    analyzer = OptimizedGooglePatentsAnalyzer(serp_api_key)
                    simplified_query = analyzer._create_ultra_simple_query(query)
                    
                    # Hacer una b√∫squeda muy simple
                    params = {
                        "engine": "google_patents",
                        "q": simplified_query,
                        "api_key": serp_api_key,
                        "num": 1
                    }
                    
                    response = requests.get(analyzer.base_url, params=params, timeout=20)
                    
                    if response.status_code == 200:
                        data = response.json()
                        if "error" not in data:
                            total_results = data.get("search_information", {}).get("total_results", 0)
                            total_results = int(str(total_results).replace(",", "")) if total_results else 0
                            
                            return {
                                "viable": total_results > 0,
                                "total_results": total_results,
                                "simplified_query": simplified_query,
                                "recommendation": "Proceder con an√°lisis" if total_results > 100 else 
                                            "Considerar ampliar t√©rminos" if total_results > 0 else 
                                            "Revisar consulta - muy espec√≠fica"
                            }
                    
                    return {"viable": False, "error": "No se pudo conectar"}
                    
                except Exception as e:
                    return {"viable": False, "error": str(e)}

            # 4. INTEGRAR VERIFICACI√ìN PREVIA EN LA INTERFAZ
            # A√±adir esto ANTES del bot√≥n principal de an√°lisis:

            # Verificaci√≥n r√°pida de viabilidad
            if scopus_query and st.session_state.get('serp_api_key') and analyze_patents:
                with st.expander("üîç Verificaci√≥n R√°pida de Patentes", expanded=False):
                    if st.button("üöÄ Verificar viabilidad (1 token)", key="verify_patents"):
                        with st.spinner("Verificando..."):
                            viability = check_patents_viability(scopus_query, st.session_state.serp_api_key)
                            
                            if viability.get("viable"):
                                st.success(f"‚úÖ {viability['recommendation']}")
                                st.info(f"üìä Aproximadamente {viability['total_results']:,} patentes encontradas")
                                st.caption(f"Query simplificada: {viability.get('simplified_query', 'N/A')}")
                            else:
                                st.warning(f"‚ö†Ô∏è {viability.get('recommendation', 'Problema detectado')}")
                                if "error" in viability:
                                    st.error(f"Error: {viability['error']}")

            # 5. CONFIGURACI√ìN MEJORADA EN EL SIDEBAR
            # A√±adir esto en la funci√≥n sidebar_config():

            # En la secci√≥n de SerpAPI, a√±adir informaci√≥n sobre optimizaci√≥n:
            with st.expander("üìà SerpAPI (Hype Cycle & Patentes)", expanded=False):
                st.markdown('<div class="api-config">', unsafe_allow_html=True)
                serp_api_key = st.text_input(
                    "SerpAPI Key",
                    value=st.session_state.serp_api_key,
                    type="password",
                    help="Necesaria para an√°lisis de Hype Cycle y b√∫squeda optimizada de patentes"
                )
                st.session_state.serp_api_key = serp_api_key
                
                # Informaci√≥n de optimizaci√≥n
                st.info("""
                **üéØ Optimizaci√≥n de Patentes:**
                - B√∫squeda inteligente por rangos
                - M√≠nimo consumo de tokens
                - Interpolaci√≥n de a√±os faltantes
                - Estrategias adaptativas por √©poca
                """)
                
                if st.button("üîÑ Probar conexi√≥n SerpAPI", key="test_serp_unique"):
                    with st.spinner("Probando conexi√≥n con SerpAPI..."):
                        success, message = test_api_connection("serp", serp_api_key)
                        if success:
                            st.success(message)
                        else:
                            st.error(message)
                st.markdown('</div>', unsafe_allow_html=True)
                                
            # =============================================================
            # 3. COMPARACI√ìN PAPERS vs PATENTES
            # =============================================================
            if papers_by_year and patents_by_year:
                st.write("## üîÑ Comparaci√≥n Papers vs Patentes")
                
                with st.spinner("üìä Generando comparaci√≥n..."):
                    # Crear DataFrame de comparaci√≥n
                    compare_years = sorted(set(list(papers_by_year.keys()) + list(patents_by_year.keys())))
                    
                    compare_data = {
                        'A√±o': compare_years,
                        'Papers': [papers_by_year.get(year, 0) for year in compare_years],
                        'Patentes': [patents_by_year.get(year, 0) for year in compare_years]
                    }
                    
                    df_compare = pd.DataFrame(compare_data)
                    
                    # Calcular acumulados
                    df_compare['Papers Acumulados'] = df_compare['Papers'].cumsum()
                    df_compare['Patentes Acumuladas'] = df_compare['Patentes'].cumsum()
                    
                    # Mostrar tabla comparativa
                    st.write("### üìä Tabla Comparativa")
                    st.dataframe(df_compare, use_container_width=True, hide_index=True)
                    
                    # Crear gr√°fico comparativo
                    fig_compare = go.Figure()
                    
                    # A√±adir l√≠neas para papers y patentes (acumulados)
                    fig_compare.add_trace(go.Scatter(
                        x=df_compare['A√±o'],
                        y=df_compare['Papers Acumulados'],
                        mode='lines+markers',
                        name='Papers (Acumulados)',
                        line=dict(color='blue', width=2)
                    ))
                    
                    fig_compare.add_trace(go.Scatter(
                        x=df_compare['A√±o'],
                        y=df_compare['Patentes Acumuladas'],
                        mode='lines+markers',
                        name='Patentes (Acumuladas)',
                        line=dict(color='red', width=2)
                    ))
                    
                    # Configurar aspecto visual
                    fig_compare.update_layout(
                        title="Comparaci√≥n de Curvas S: Papers vs Patentes",
                        xaxis_title="A√±o",
                        yaxis_title="Cantidad Acumulada",
                        legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='center', x=0.5),
                        plot_bgcolor='white',
                        xaxis=dict(showgrid=True, gridcolor='lightgray'),
                        yaxis=dict(showgrid=True, gridcolor='lightgray')
                    )
                    
                    # Mostrar gr√°fico
                    st.plotly_chart(fig_compare, use_container_width=True)
                    
                    # =============================================================
                    # 4. AN√ÅLISIS DE BRECHA TEMPORAL (TIME LAG)
                    # =============================================================
                    st.write("### üï∞Ô∏è An√°lisis de Brecha Temporal (Time Lag)")
                    
                    if (papers_analysis and patents_analysis and 
                        papers_analysis['metrics'] and patents_analysis['metrics'] and
                        'x0' in papers_analysis['metrics'] and 'x0' in patents_analysis['metrics']):
                        
                        # Calcular brecha entre puntos de inflexi√≥n
                        papers_inflection = papers_analysis['metrics']['x0']
                        patents_inflection = patents_analysis['metrics']['x0']
                        time_lag = patents_inflection - papers_inflection
                        
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric(
                                "Punto de inflexi√≥n Papers", 
                                f"{papers_inflection:.1f}",
                                help="A√±o estimado del punto de inflexi√≥n para publicaciones acad√©micas"
                            )
                        
                        with col2:
                            st.metric(
                                "Punto de inflexi√≥n Patentes", 
                                f"{patents_inflection:.1f}",
                                help="A√±o estimado del punto de inflexi√≥n para patentes"
                            )
                        
                        with col3:
                            delta_color = "normal" if abs(time_lag) < 1 else ("inverse" if time_lag > 0 else "off")
                            st.metric(
                                "Time Lag (a√±os)", 
                                f"{time_lag:.1f}",
                                delta=f"{'+' if time_lag > 0 else ''}{time_lag:.1f}",
                                help="Diferencia temporal entre los puntos de inflexi√≥n"
                            )
                        
                        # Interpretaci√≥n del time lag
                        if time_lag > 2:
                            st.info(f"üîç **Interpretaci√≥n**: Las patentes muestran un retraso significativo de {time_lag:.1f} a√±os respecto a las publicaciones acad√©micas. Esto sugiere que la investigaci√≥n acad√©mica ha precedido considerablemente a la comercializaci√≥n de esta tecnolog√≠a.")
                        elif time_lag < -2:
                            st.info(f"üîç **Interpretaci√≥n**: Las patentes muestran un adelanto significativo de {abs(time_lag):.1f} a√±os respecto a las publicaciones acad√©micas. Esto sugiere que la comercializaci√≥n ha precedido a la investigaci√≥n acad√©mica profunda en esta tecnolog√≠a.")
                        else:
                            st.info("üîç **Interpretaci√≥n**: No hay brecha temporal significativa entre publicaciones acad√©micas y patentes, sugiriendo un desarrollo relativamente paralelo entre investigaci√≥n y comercializaci√≥n.")
                    else:
                        st.warning("No se pudieron calcular los puntos de inflexi√≥n para ambas curvas.")
                
                # Exportar comparaci√≥n completa
                st.write("### üì• Exportar Comparaci√≥n Completa")
                combined_csv = df_compare.to_csv(index=False)
                st.download_button(
                    label="üìä Descargar Comparaci√≥n Completa (CSV)",
                    data=combined_csv,
                    file_name=f"comparacion_papers_patents_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                    mime="text/csv",
                    key="download_comparison_complete_csv"
                )
            
            # Opci√≥n para guardar an√°lisis completo
            _show_save_analysis_option(scopus_query, papers_by_year, patents_by_year, papers_analysis, patents_analysis)
    
    # =================================================================
    # PESTA√ëA 2: CARGA MANUAL (EXCEL)
    # =================================================================
    with tab2:
        st.header("üì§ Carga Manual de Datos")
        st.write("""
        **M√©todo auxiliar:** Si necesitas datos m√°s espec√≠ficos, de fuentes adicionales, 
        o quieres complementar los resultados autom√°ticos, puedes usar plantillas Excel.
        """)
        
        # Subtabs para papers y patentes
        excel_tab1, excel_tab2 = st.tabs(["üìÑ Papers (Excel)", "üìë Patentes (Excel)"])
        
        with excel_tab1:
            st.write("### üìÑ Carga Manual de Papers")
            st.info("Esta funcionalidad permite cargar datos de papers desde Excel si tienes fuentes adicionales.")
            st.write("*Pr√≥ximamente: Plantilla para carga manual de papers*")
        
        with excel_tab2:
            st.write("### üìë Carga Manual de Patentes")
            _show_excel_patents_interface()

# =================================================================
# FUNCIONES AUXILIARES
# =================================================================

def _show_save_analysis_option(query, papers_data, patents_data, papers_analysis, patents_analysis):
    """Muestra opciones para guardar el an√°lisis completo"""
    if papers_data or patents_data:
        with st.expander("üíæ Guardar An√°lisis Completo", expanded=False):
            st.write("Guarda este an√°lisis para futuras comparaciones y referencias.")
            
            # Mostrar resumen de datos disponibles
            available_data = []
            if papers_data:
                available_data.append(f"‚úÖ Papers: {sum(papers_data.values())} publicaciones")
            if patents_data:
                available_data.append(f"‚úÖ Patentes: {sum(patents_data.values())} patentes")
            
            st.info("**Datos disponibles para guardar:**\n" + "\n".join(available_data))
            
            # Formulario para guardar
            with st.form("save_complete_analysis_form"):
                analysis_name = st.text_input(
                    "Nombre para este an√°lisis",
                    value=f"An√°lisis completo - {query[:30]}..." if len(query) > 30 else f"An√°lisis completo - {query}"
                )
                
                save_method = st.radio(
                    "M√©todo de guardado",
                    options=["Sistema de Base de Datos", "Archivo directo"],
                    index=0
                )
                
                submit = st.form_submit_button("üíæ Guardar An√°lisis Completo", type="primary")
                
                if submit and analysis_name:
                    _save_complete_analysis(
                        analysis_name, query, papers_data, patents_data, 
                        papers_analysis, patents_analysis, save_method
                    )

def _show_excel_patents_interface():
    """Interfaz para carga manual de patentes via Excel"""
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("#### üìã Descargar Plantilla")
        
        start_year = st.number_input(
            "A√±o inicial", 
            min_value=1900,
            max_value=datetime.now().year - 5,
            value=1920,
            key="excel_start_year"
        )
        
        end_year = st.number_input(
            "A√±o final", 
            min_value=start_year + 5,
            max_value=datetime.now().year,
            value=datetime.now().year,
            key="excel_end_year"
        )
        
        template_bytes = PatentDataManager.create_template(start_year, end_year)
        
        st.download_button(
            label="üì• Descargar Plantilla Excel",
            data=template_bytes,
            file_name=f"plantilla_patentes_{start_year}-{end_year}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="download_excel_template_manual"
        )
    
    with col2:
        st.write("#### üì§ Subir Archivo")
        
        uploaded_file = st.file_uploader(
            "Selecciona archivo Excel",
            type=["xlsx", "xls"],
            key="excel_file_uploader_manual"
        )
        
        if uploaded_file is not None:
            patents_data = PatentDataManager.load_data(uploaded_file)
            
            if patents_data:
                st.success("‚úÖ Archivo cargado correctamente")
                
                # Mostrar an√°lisis inmediato
                df_patents = TechnologyAnalyzer.display_data_table(
                    patents_data, 
                    title="Datos de Patentes Cargados"
                )
                
                analysis_df, analysis_fig, ajuste_info, parametros = TechnologyAnalyzer.analyze_s_curve(patents_data)
                
                TechnologyAnalyzer.display_s_curve_analysis(
                    analysis_df, analysis_fig, ajuste_info, parametros,
                    title="An√°lisis de Curva en S - Patentes (Excel)"
                )
                
                TechnologyAnalyzer.export_data(
                    analysis_df if analysis_df is not None else df_patents,
                    "patentes_excel",
                    "datos_manuales"
                )

def _save_complete_analysis(name, query, papers_data, patents_data, papers_analysis, patents_analysis, method):
    """Guarda el an√°lisis completo"""
    try:
        if method == "Sistema de Base de Datos":
            from data_storage import initialize_github_db
            
            db = initialize_github_db(use_local=True)
            if db:
                paper_metrics = papers_analysis['metrics'] if papers_analysis else None
                patent_metrics = patents_analysis['metrics'] if patents_analysis else None
                
                analysis_id = db.save_s_curve_analysis(
                    query=query,
                    paper_data=papers_data,
                    patent_data=patents_data,
                    paper_metrics=paper_metrics,
                    patent_metrics=patent_metrics,
                    analysis_name=name
                )
                
                if analysis_id:
                    st.success(f"‚úÖ An√°lisis completo guardado con ID: {analysis_id}")
                else:
                    st.error("‚ùå Error al guardar en base de datos")
            else:
                st.error("‚ùå No se pudo inicializar el sistema de base de datos")
        
        else:  # Archivo directo
            from data_storage import save_analysis_direct
            
            paper_metrics = papers_analysis['metrics'] if papers_analysis else None
            patent_metrics = patents_analysis['metrics'] if patents_analysis else None
            
            result = save_analysis_direct(
                analysis_name=name,
                query=query,
                paper_data=papers_data,
                patent_data=patents_data,
                paper_metrics=paper_metrics,
                patent_metrics=patent_metrics
            )
            
            if result:
                st.success(f"‚úÖ An√°lisis guardado en: {result}")
            else:
                st.error("‚ùå Error al guardar archivo directo")
                
    except Exception as e:
        st.error(f"‚ùå Error al guardar: {str(e)}")

def add_direct_save_option(analysis_name, query, paper_data=None, patent_data=None, paper_metrics=None, patent_metrics=None):
    """
    A√±ade una opci√≥n para guardar directamente los datos del an√°lisis.
    """
    from data_storage import save_analysis_direct
    
    if st.button("üíæ Guardar datos directamente", type="primary", key="save_direct_analysis"):
        result = save_analysis_direct(
            analysis_name=analysis_name,
            query=query,
            paper_data=paper_data,
            patent_data=patent_data,
            paper_metrics=paper_metrics,
            patent_metrics=patent_metrics
        )
        
        if result:
            st.success(f"Datos guardados correctamente en: {result}")
            # Mostrar opci√≥n para descargar el archivo
            try:
                with open(result, 'r', encoding='utf-8') as f:
                    file_content = f.read()
                    
                st.download_button(
                    label="üì• Descargar archivo JSON",
                    data=file_content,
                    file_name=os.path.basename(result),
                    mime="application/json",
                    key=f"download_json_direct_{int(time.time())}"  # ‚Üê KEY √öNICO AGREGADO
                )
            except Exception as e:
                st.warning(f"No se pudo preparar descarga: {str(e)}")

if __name__ == "__main__":
    run_s_curve_analysis()