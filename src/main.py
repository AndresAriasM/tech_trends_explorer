# src/main.py
import streamlit as st
import os
from dotenv import load_dotenv
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
import base64
import io
from datetime import datetime
from reportlab.lib import colors
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from io import BytesIO
from analysis import QueryBuilder, ResultAnalyzer, NewsAnalyzer
from config import CONFIG

# Cargar variables de entorno
load_dotenv()

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Tech Trends Explorer",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Estilos CSS personalizados
st.markdown("""
    <style>
        .main-header {
            font-size: 2.5rem;
            font-weight: bold;
            margin-bottom: 2rem;
        }
        .stButton button {
            width: 100%;
        }
        .results-container {
            background-color: #f0f2f6;
            padding: 1.5rem;
            border-radius: 0.5rem;
        }
        .metric-card {
            background-color: white;
            padding: 1rem;
            border-radius: 0.3rem;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
    </style>
""", unsafe_allow_html=True)

def reset_session_state():
    """Resetea todas las variables de estado de la sesi√≥n"""
    for key in list(st.session_state.keys()):
        if key != 'num_topics':  # Mantener solo el contador de topics
            del st.session_state[key]

def test_api_connection(api_key, search_engine_id):
    try:
        print(f"Probando con API Key: {api_key[:10]}... y Search Engine ID: {search_engine_id}")
        service = build("customsearch", "v1", developerKey=api_key)
        print("Servicio creado exitosamente")
        
        result = service.cse().list(
            q="test",
            cx=search_engine_id,
            num=1
        ).execute()
        print("B√∫squeda ejecutada exitosamente")
        print(f"Resultados obtenidos: {result.get('searchInformation', {}).get('totalResults', 'N/A')}")
        
        return True, "Conexi√≥n exitosa"
    except HttpError as e:
        error_details = str(e)
        print(f"Error HTTP: {error_details}")
        
        if e.resp.status == 403:
            return False, f"Error de autenticaci√≥n (403): {error_details}"
        elif e.resp.status == 400:
            return False, f"Error en la configuraci√≥n (400): {error_details}"
        else:
            return False, f"Error HTTP {e.resp.status}: {error_details}"
    except Exception as e:
        print(f"Error inesperado: {str(e)}")
        return False, f"Error inesperado: {str(e)}"

def perform_search(api_key, search_engine_id, query, content_types, max_results=100):
    """
    Realiza b√∫squedas en Google Custom Search respetando el l√≠mite de resultados especificado
    """
    try:
        service = build("customsearch", "v1", developerKey=api_key)
        all_results = []
        
        # Construir filtros basados en los tipos de contenido seleccionados
        type_filters = []
        base_query = query

        if content_types.get('academic', False):
            type_filters.append('site:scholar.google.com OR site:sciencedirect.com OR site:springer.com OR site:ieee.org')
        if content_types.get('news', False):
            type_filters.append('site:news.google.com OR site:reuters.com OR site:bloomberg.com')
        if content_types.get('pdfs', False):
            type_filters.append('filetype:pdf')
        if not content_types.get('patents', False):
            base_query += ' -patent -uspto.gov -espacenet'

        # Combinar query con filtros
        if type_filters:
            final_query = f"({base_query}) AND ({' OR '.join(type_filters)})"
        else:
            final_query = base_query

        # Calcular n√∫mero total de p√°ginas necesarias
        total_pages = (max_results + 9) // 10
        
        # Debug: Mostrar informaci√≥n de la b√∫squeda
        st.write(f"Buscando hasta {max_results} resultados en {total_pages} p√°ginas")
        
        # Crear barra de progreso
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for page in range(total_pages):
            start_index = (page * 10) + 1
            
            # Actualizar estado
            progress = (page + 1) / total_pages
            progress_bar.progress(progress)
            status_text.text(f"Obteniendo resultados... P√°gina {page + 1} de {total_pages} ({len(all_results)} resultados encontrados)")
            
            try:
                result = service.cse().list(
                    q=final_query,
                    cx=search_engine_id,
                    num=min(10, max_results - len(all_results)),  # No pedir m√°s de los necesarios
                    start=start_index
                ).execute()
                
                items = result.get('items', [])
                if not items:
                    break
                    
                all_results.extend(items)
                
                # Verificar si ya tenemos suficientes resultados
                if len(all_results) >= max_results:
                    all_results = all_results[:max_results]
                    break
                
            except Exception as e:
                st.warning(f"Error en p√°gina {page + 1}: {str(e)}")
                break  # Si hay error, detenemos la b√∫squeda
        
        # Limpiar indicadores de progreso
        progress_bar.empty()
        status_text.empty()
        
        # Informar resultados obtenidos
        st.info(f"B√∫squeda completada: {len(all_results)} resultados encontrados")
        
        return True, all_results
    except Exception as e:
        st.error(f"Error en la b√∫squeda: {str(e)}")
        return False, str(e)

def show_analysis_results(results, query_info, search_topics, content_types, hype_data=None, hype_figures=None):
    # Crear instancia del analizador
    analyzer = ResultAnalyzer()
    processed_results, stats = analyzer.analyze_results(results, search_topics)
    
    # Funci√≥n para determinar el tipo de resultado
    def get_result_type(result):
        url = result['link'].lower()
        title = result['title'].lower()
        
        if any(term in url for term in ['.pdf', '/pdf/']):
            return 'pdf'
        elif any(term in url for term in ['patent', 'uspto.gov', 'espacenet']):
            return 'patent'
        elif any(term in url for term in ['scholar.google', 'sciencedirect', 'springer', 'ieee']):
            return 'academic'
        elif any(term in url for term in ['news.google', 'reuters', 'bloomberg']):
            return 'news'
        return 'web'

    # Filtrar resultados seg√∫n las selecciones del sidebar
    filtered_results = []
    for result in processed_results:
        result_type = get_result_type(result)
        
        # Aplicar filtros seg√∫n el tipo
        if (
            (result_type == 'pdf' and content_types.get('pdfs', True)) or
            (result_type == 'academic' and content_types.get('academic', True)) or
            (result_type == 'news' and content_types.get('news', True)) or
            (result_type == 'patent' and content_types.get('patents', True)) or
            (result_type == 'web')  # Web siempre se muestra
        ):
            filtered_results.append(result)

    # Estados iniciales para la b√∫squeda en resultados
    if 'search_query' not in st.session_state:
        st.session_state.search_query = ''
    if 'search_results' not in st.session_state:
        st.session_state.search_results = filtered_results

    # Funci√≥n para actualizar resultados de b√∫squeda
    def update_search():
        if st.session_state.search_query:
            st.session_state.search_results = [
                result for result in filtered_results
                if st.session_state.search_query.lower() in result['title'].lower()
            ]
        else:
            st.session_state.search_results = filtered_results

    # Mostrar ecuaciones de b√∫squeda
    with st.expander("üìù Ver ecuaciones de b√∫squeda", expanded=True):
        st.write("##### Ecuaci√≥n de b√∫squeda en Google:")
        st.code(query_info['google_query'])
        st.write("##### Ecuaci√≥n de b√∫squeda en Scopus:")
        st.code(query_info['scopus_query'])


    # Mostrar conteo de resultados
    total_results = len(processed_results)
    filtered_count = len(filtered_results)
    search_count = len(st.session_state.search_results)

    if filtered_count < total_results:
        st.info(f"Mostrando {filtered_count} de {total_results} resultados (filtrados por tipo de contenido)")
    
    if st.session_state.search_query:
        st.info(f"Encontrados {search_count} resultados que coinciden con la b√∫squeda")
    
    # Calcular distribuci√≥n de tipos de contenido
    content_distribution = {}
    for result in filtered_results:
        result_type = get_result_type(result).upper()
        content_distribution[result_type] = content_distribution.get(result_type, 0) + 1

    # Gr√°ficos de distribuci√≥n
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("### üìä Distribuci√≥n por tipo de contenido")
        fig_type = px.pie(
            values=list(content_distribution.values()),
            names=list(content_distribution.keys()),
            title=f"Distribuci√≥n de {filtered_count} resultados por tipo"
        )
        fig_type.update_traces(
            textposition='inside',
            textinfo='percent+label+value',
            marker_colors=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']  # Colores personalizados
        )
        fig_type.update_layout(
            showlegend=True,
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
        )
        st.plotly_chart(fig_type, use_container_width=True)
        
        # Mostrar tabla de distribuci√≥n bajo el gr√°fico
        st.write("#### Detalle de distribuci√≥n:")
        distribution_data = pd.DataFrame(
            {
                'Tipo': list(content_distribution.keys()),
                'Cantidad': list(content_distribution.values()),
                'Porcentaje': [f"{(v/filtered_count)*100:.1f}%" for v in content_distribution.values()]
            }
        )
        st.dataframe(distribution_data, hide_index=True)
    
    with col2:
        st.write("### üìà Tendencia temporal")
        if stats['by_year']:
            fig_year = px.bar(
                x=list(stats['by_year'].keys()),
                y=list(stats['by_year'].values()),
                title="Distribuci√≥n por a√±o"
            )
            fig_year.update_xaxes(title="A√±o")
            fig_year.update_yaxes(title="Cantidad")
            st.plotly_chart(fig_year, use_container_width=True)


    # M√©tricas y gr√°ficos...
    # Gr√°fico de palabras clave
    st.write("### üè∑Ô∏è Palabras clave m√°s frecuentes")
    if stats['common_keywords']:
        keywords_df = pd.DataFrame(stats['common_keywords'], columns=['Keyword', 'Count'])
        fig_keywords = px.bar(
            keywords_df.head(10),
            x='Keyword',
            y='Count',
            title="T√©rminos m√°s frecuentes en los resultados"
        )
        fig_keywords.update_layout(
            xaxis_title="Palabras clave",
            yaxis_title="Frecuencia",
            showlegend=False
        )
        st.plotly_chart(fig_keywords, use_container_width=True)
    
    # Bot√≥n de descarga
    st.write("### üì• Exportar Resultados")
    
    # Combinar todas las figuras
    all_figures = {
        "Distribuci√≥n por Tipo": fig_type,
        "Tendencia Temporal": fig_year,
        "Palabras Clave": fig_keywords
    }
    
    # Agregar figuras del Hype Cycle si existen
    if hype_figures:
        all_figures.update(hype_figures)
    
    # Usar session state para evitar recargas
    if 'pdf_generated' not in st.session_state:
        st.session_state.pdf_generated = False
    
    download_col1, download_col2 = st.columns([3, 1])
    
    with download_col1:
        try:
            pdf_data = export_to_pdf(
                results=results,
                query_info=query_info,
                hype_data=hype_data,
                figures=all_figures
            )
            
            if st.download_button(
                label="üì• Descargar Informe Completo (PDF)",
                data=pdf_data,
                file_name=f"analisis_tendencias_{datetime.now().strftime('%Y%m%d_%H%M')}.pdf",
                mime="application/pdf",
                key=f"download_pdf_{datetime.now().timestamp()}",  # Key √∫nica
                on_click=lambda: setattr(st.session_state, 'pdf_generated', True)
            ):
                pass  # No hacemos nada aqu√≠ para evitar recargas
                
        except Exception as e:
            st.error(f"Error al generar el PDF: {str(e)}")
    
    with download_col2:
        if st.session_state.pdf_generated:
            st.success("‚úÖ Listo!")

    # Mostrar resultados
    st.write("### üìë Resultados detallados")
    results_to_show = st.session_state.search_results
    
    if not results_to_show:
        st.warning("No se encontraron resultados que coincidan con los filtros actuales")
    else:
        for result in results_to_show:
            with st.expander(f"üìÑ {result['title']}", expanded=False):
                col1, col2 = st.columns([2,1])
                with col1:
                    st.markdown("**Descripci√≥n:**")
                    st.write(result['snippet'])
                    st.markdown(f"üîó [Ver documento completo]({result['link']})")
                with col2:
                    st.markdown("**Detalles:**")
                    st.markdown(f"üìÖ **A√±o:** {result.get('year', 'No especificado')}")
                    st.markdown(f"üåç **Pa√≠s:** {result.get('country', 'No especificado')}")
                    tipo = get_result_type(result).upper()
                    st.markdown(f"üìä **Tipo:** {tipo}")

def export_to_pdf(results, query_info, hype_data, figures, news_results=None):
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=letter)
    styles = getSampleStyleSheet()
    story = []

    # Estilos personalizados
    styles.add(ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontSize=24,
        spaceAfter=30
    ))
    
    styles.add(ParagraphStyle(
        'SectionTitle',
        parent=styles['Heading2'],
        fontSize=16,
        spaceBefore=15,
        spaceAfter=10
    ))

    # T√≠tulo y fecha
    story.append(Paragraph('An√°lisis de Tendencias Tecnol√≥gicas', styles['CustomTitle']))
    story.append(Paragraph(f'Generado el {datetime.now().strftime("%d-%m-%Y %H:%M")}', styles['Normal']))
    story.append(Spacer(1, 20))

    # Ecuaciones de b√∫squeda
    story.append(Paragraph('Ecuaciones de B√∫squeda', styles['SectionTitle']))
    story.append(Paragraph(f'<b>Google:</b> {query_info["google_query"]}', styles['Normal']))
    story.append(Paragraph(f'<b>Scopus:</b> {query_info["scopus_query"]}', styles['Normal']))
    story.append(Spacer(1, 20))

    # M√©tricas y estad√≠sticas
    story.append(Paragraph('Estad√≠sticas Generales', styles['SectionTitle']))
    story.append(Paragraph(f'Total de resultados encontrados: {len(results)}', styles['Normal']))
    story.append(Spacer(1, 12))

    # Gr√°ficos de an√°lisis general
    for name, fig in figures.items():
        story.append(Paragraph(name, styles['SectionTitle']))
        img_bytes = BytesIO()
        fig.write_image(img_bytes, format='png', width=600, height=400)
        img = Image(img_bytes, width=6*inch, height=4*inch)
        story.append(img)
        story.append(Spacer(1, 12))

    # En la funci√≥n export_to_pdf, despu√©s de los gr√°ficos generales
    if hype_data and isinstance(hype_data, dict):
        story.append(Paragraph('An√°lisis del Hype Cycle de Gartner', styles['SectionTitle']))
        story.append(Paragraph(f'<b>Fase Actual:</b> {hype_data["phase"]}', styles['Normal']))
        
        # Agregar todos los gr√°ficos relacionados con Gartner
        for name, fig in figures.items():
            if any(term in name.lower() for term in ['hype', 'menciones', 'sentimiento']):
                story.append(Paragraph(name, styles['SectionTitle']))
                img_bytes = BytesIO()
                fig.write_image(img_bytes, format='png', width=600, height=400)
                img = Image(img_bytes, width=6*inch, height=4*inch)
                story.append(img)
                story.append(Spacer(1, 12))
                
    # An√°lisis del Hype Cycle
    if hype_data:
        story.append(Paragraph('An√°lisis del Hype Cycle de Gartner', styles['SectionTitle']))
        story.append(Paragraph(f'<b>Fase Actual:</b> {hype_data["phase"]}', styles['Normal']))
        
        # Descripci√≥n de la fase
        phase_descriptions = {
            "Innovation Trigger": """La tecnolog√≠a est√° en su fase inicial de innovaci√≥n, caracterizada por:
            ‚Ä¢ Alto nivel de inter√©s y especulaci√≥n
            ‚Ä¢ Pocos casos de implementaci√≥n real
            ‚Ä¢ Gran potencial percibido""",
            "Peak of Inflated Expectations": """La tecnolog√≠a est√° en su punto m√°ximo de expectativas, donde se observa:
            ‚Ä¢ M√°xima cobertura medi√°tica
            ‚Ä¢ Altas expectativas de mercado
            ‚Ä¢ Posible sobreestimaci√≥n de capacidades""",
            "Trough of Disillusionment": """La tecnolog√≠a est√° atravesando una fase de desilusi√≥n, caracterizada por:
            ‚Ä¢ Disminuci√≥n del inter√©s inicial
            ‚Ä¢ Identificaci√≥n de limitaciones reales
            ‚Ä¢ Reevaluaci√≥n de expectativas""",
            "Slope of Enlightenment": """La tecnolog√≠a est√° madurando hacia una comprensi√≥n realista, donde se observa:
            ‚Ä¢ Casos de uso bien definidos
            ‚Ä¢ Beneficios comprobados
            ‚Ä¢ Adopci√≥n m√°s estrat√©gica""",
            "Plateau of Productivity": """La tecnolog√≠a ha alcanzado un nivel de madurez estable, caracterizada por:
            ‚Ä¢ Adopci√≥n generalizada
            ‚Ä¢ Beneficios claramente demostrados
            ‚Ä¢ Implementaci√≥n sistem√°tica"""
        }
        story.append(Paragraph(phase_descriptions[hype_data['phase']], styles['Normal']))
        story.append(Spacer(1, 12))
        
        # M√©tricas del Hype Cycle
        if 'yearly_stats' in hype_data:
            yearly_stats = hype_data['yearly_stats']
            story.append(Paragraph('M√©tricas de An√°lisis', styles['SectionTitle']))
            story.append(Paragraph(f"<b>Total de Menciones:</b> {yearly_stats['mention_count'].sum()}", styles['Normal']))
            avg_sentiment = yearly_stats['sentiment_mean'].mean()
            sentiment_label = "Positivo" if avg_sentiment > 0 else "Negativo"
            story.append(Paragraph(f"<b>Sentimiento Promedio:</b> {avg_sentiment:.2f} ({sentiment_label})", styles['Normal']))
            
            trend = yearly_stats['mention_count'].pct_change().mean()
            trend_label = "Creciente" if trend > 0 else "Decreciente"
            story.append(Paragraph(f"<b>Tendencia:</b> {trend_label} ({trend:.1%})", styles['Normal']))

    # Resultados detallados
    story.append(Paragraph('Resultados Detallados', styles['SectionTitle']))
    for result in results:
        story.append(Paragraph(result['title'], styles['Heading3']))
        story.append(Paragraph(result.get('snippet', 'No hay descripci√≥n disponible'), styles['Normal']))
        story.append(Paragraph(f'<link href="{result["link"]}">{result["link"]}</link>', styles['Normal']))
        if result.get('year'):
            story.append(Paragraph(f'<b>A√±o:</b> {result["year"]}', styles['Normal']))
        story.append(Spacer(1, 12))

    # Construir PDF
    doc.build(story)
    buffer.seek(0)
    return buffer.getvalue()

def sidebar_config():
    with st.sidebar:
        st.header("‚öôÔ∏è Configuraci√≥n")
        
        # API Keys
        api_key = st.text_input(
            "Google API Key",
            value=os.getenv('GOOGLE_API_KEY', ''),
            type="password"
        )
        search_engine_id = st.text_input(
            "Search Engine ID",
            value=os.getenv('SEARCH_ENGINE_ID', ''),
            type="password"
        )
        serp_api_key = st.text_input(
            "SerpAPI Key",
            value=os.getenv('SERP_API_KEY', ''),
            type="password",
            help="API key para SerpAPI (usado en an√°lisis Hype Cycle)"
        )
        
        # Bot√≥n de prueba
        if st.button("üîÑ Probar conexi√≥n"):
            with st.spinner("Probando conexi√≥n..."):
                # Probar Google API
                success_google, message_google = test_api_connection(api_key, search_engine_id)
                
                # Probar SerpAPI
                success_serp, message_serp = test_serp_api_connection(serp_api_key)
                
                if success_google and success_serp:
                    st.success("Todas las conexiones exitosas")
                else:
                    if not success_google:
                        st.error(f"Error en Google API: {message_google}")
                    if not success_serp:
                        st.error(f"Error en SerpAPI: {message_serp}")
        
        st.divider()
        
        # Configuraci√≥n de b√∫squeda
        st.subheader("üîç Configuraci√≥n de B√∫squeda")
        
        # N√∫mero de resultados con mayor rango
        col1, col2 = st.columns(2)
        with col1:
            max_results = st.number_input(
                "N√∫mero de resultados",
                min_value=10,
                max_value=1000,
                value=10,
                step=10,
                help="N√∫mero total de resultados a obtener"
            )
        with col2:
            st.info(f"Consultas API: {(max_results + 9) // 10}")
        
        st.caption("‚ö†Ô∏è Cada 10 resultados = 1 consulta API")
        
        # Filtros de contenido
        st.subheader("üìë Tipos de Contenido")
        content_types = {
            'academic': st.checkbox("Art√≠culos Acad√©micos", value=True, help="Incluir resultados de Google Scholar y otros repositorios acad√©micos"),
            'news': st.checkbox("Noticias", value=True, help="Incluir art√≠culos de noticias y medios"),
            'pdfs': st.checkbox("PDFs", value=True, help="Incluir documentos PDF"),
            'patents': st.checkbox("Patentes", value=True, help="Incluir patentes relacionadas")
        }
        
        # Filtros temporales
        st.divider()
        st.subheader("üìÖ Filtros Temporales")
        
        min_year = st.number_input(
            "A√±o m√≠nimo",
            min_value=1970,
            max_value=2025,
            value=2014,
            help="A√±o desde el cual buscar resultados"
        )
        
        st.divider()
        api_usage = st.expander("‚ÑπÔ∏è Informaci√≥n de uso de API")
        with api_usage:
            st.write("""
            - L√≠mite diario gratuito: 100 consultas
            - Cada 10 resultados = 1 consulta
            - M√°ximo 100 resultados por consulta
            - Los resultados se obtienen en p√°ginas de 10
            """)
        
        return {
            'api_key': api_key,
            'search_engine_id': search_engine_id,
            'serp_api_key': serp_api_key,
            'min_year': min_year,
            'content_types': content_types,
            'max_results': max_results
        }
        

def perform_advanced_search(api_key, search_engine_id, query, config):
    try:
        service = build("customsearch", "v1", developerKey=api_key)
        all_results = []
        seen_urls = set()  # Para controlar duplicados
        desired_results = config['desired_results']
        
        # Modificar query seg√∫n tipos de contenido permitidos
        content_filters = []
        if config['content_types']['academic']:
            content_filters.extend(['site:scholar.google.com OR site:sciencedirect.com OR site:springer.com OR site:ieee.org'])
        if config['content_types']['news']:
            content_filters.extend(['site:news.google.com OR site:reuters.com OR site:bloomberg.com'])
        if config['content_types']['pdfs']:
            content_filters.append('filetype:pdf')
        if not config['content_types']['patents']:
            content_filters.append('-patent')
        
        # Agregar filtros al query original
        if content_filters:
            query = f"({query}) AND ({' OR '.join(content_filters)})"
        
        # Iniciar barra de progreso
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        page = 1
        total_requested = 0
        
        while len(all_results) < desired_results:
            try:
                start_index = ((page - 1) * 10) + 1
                
                status_text.text(f"Buscando resultados... (P√°gina {page})")
                
                result = service.cse().list(
                    q=query,
                    cx=search_engine_id,
                    num=10,
                    start=start_index
                ).execute()
                
                items = result.get('items', [])
                if not items:
                    break
                
                # Filtrar duplicados y procesar resultados
                for item in items:
                    url = item.get('link')
                    if url not in seen_urls:
                        # Verificar tipo de contenido
                        content_type = classify_content_type(item)
                        if should_include_content(content_type, config['content_types']):
                            seen_urls.add(url)
                            all_results.append(item)
                
                # Actualizar progreso
                progress = min(len(all_results) / desired_results, 1.0)
                progress_bar.progress(progress)
                
                page += 1
                total_requested += 10
                
                # Evitar exceder l√≠mites de API
                if total_requested >= 100:  # L√≠mite de 100 resultados por consulta
                    status_text.warning("Se alcanz√≥ el l√≠mite de resultados por consulta")
                    break
                
            except Exception as e:
                status_text.error(f"Error en p√°gina {page}: {str(e)}")
                break
        
        status_text.text(f"B√∫squeda completada. Se encontraron {len(all_results)} resultados √∫nicos.")
        return True, all_results
        
    except Exception as e:
        return False, str(e)

def classify_content_type(item):
    """Clasificar el tipo de contenido basado en la URL y metadata"""
    url = item.get('link', '').lower()
    title = item.get('title', '').lower()
    
    if 'pdf' in url or any(mime in item.get('mime', '') for mime in ['pdf', 'application/pdf']):
        return 'PDF'
    elif any(domain in url for domain in ['scholar.google', 'sciencedirect', 'springer', 'ieee']):
        return 'Academic'
    elif any(domain in url for domain in ['news.google', 'reuters', 'bloomberg']):
        return 'News'
    elif any(term in url for term in ['patent', 'uspto.gov', 'espacenet']):
        return 'Patent'
    else:
        return 'Web Page'

def should_include_content(content_type, content_types):
    """Determinar si un tipo de contenido debe ser incluido seg√∫n la configuraci√≥n"""
    mapping = {
        'Web Page': 'web_pages',
        'Academic': 'academic',
        'News': 'news',
        'PDF': 'pdfs',
        'Patent': 'patents'
    }
    return content_types.get(mapping.get(content_type, 'web_pages'), False)

def main():
    # Cargar configuraci√≥n
    config = sidebar_config()
    
    # Encabezado principal
    st.markdown('<p class="main-header">üîç Tech Trends Explorer</p>', unsafe_allow_html=True)
    
    # Verificar configuraci√≥n
    if not config['api_key'] or not config['search_engine_id'] or not config['serp_api_key']:
        st.warning("‚ö†Ô∏è Por favor, configura todas las credenciales de API en el sidebar")
        return
    
    # √Årea de b√∫squeda
    st.write("### üéØ Define tus t√©rminos de b√∫squeda")
    
    # Topics din√°micos
    if 'num_topics' not in st.session_state:
        st.session_state.num_topics = 1
    
    topics = []
    for i in range(st.session_state.num_topics):
        topic = st.text_input(
            f"Tema {i+1}",
            key=f"topic_{i}",
            placeholder="Ej: Artificial Intelligence, Blockchain, IoT..."
        )
        if topic.strip():  # Solo a√±adir temas no vac√≠os
            topics.append(topic)
    
    if st.button("+ A√±adir otro tema"):
        st.session_state.num_topics += 1
        st.rerun()
    
    # Bot√≥n de b√∫squeda
    if st.button("üîç Analizar Tendencias", type="primary"):
        reset_session_state()
        if not topics:
            st.error("Por favor, ingresa al menos un tema para buscar")
            return
            
        with st.spinner("üîÑ Analizando tendencias tecnol√≥gicas..."):
            # Inicializar analizadores
            query_builder = QueryBuilder()
            news_analyzer = NewsAnalyzer()
            
            # Construir query principal
            google_query = query_builder.build_google_query(
                topics, 
                config['min_year'],
                config['content_types']['patents']
            )
            
            # Crear objeto de informaci√≥n de queries
            query_info = {
                'google_query': google_query,  # La clave existente
                'scopus_query': query_builder.build_scopus_query(topics, config['min_year']),  # La clave existente
                'search_query': google_query,  # Nueva clave para display_advanced_analysis
                'time_range': f"{CONFIG['MIN_YEAR']}-{datetime.now().year}"
            }
            
            # Crear pesta√±as
            tab1, tab2 = st.tabs(["üìä An√°lisis General", "üìà An√°lisis Hype Cycle"])

            with tab1:
                # Realizar b√∫squeda general con Google API
                success, general_results = perform_search(
                    config['api_key'], 
                    config['search_engine_id'], 
                    google_query,
                    config['content_types'],
                    max_results=config['max_results']
                )
                
                if success:
                    # Mostrar resultados generales
                    show_analysis_results(
                        results=general_results,
                        query_info=query_info,
                        search_topics=topics,
                        content_types=config['content_types']
                    )
                else:
                    st.error("Error en la b√∫squeda general de tendencias")
            
            with tab2:
                st.write("### üìà An√°lisis del Hype Cycle")
                
                with st.spinner("Analizando datos con SerpAPI..."):
                    # Realizar b√∫squeda espec√≠fica para Hype Cycle
                    serp_success, serp_results = news_analyzer.perform_news_search(
                        serp_api_key=config['serp_api_key'],
                        query=google_query
                    )
                    
                    if serp_success and serp_results:
                        # An√°lisis del Hype Cycle
                        hype_data = news_analyzer.analyze_hype_cycle(serp_results)
                        
                        if hype_data:
                            # Mostrar fase actual
                            st.success(f"**Fase Actual:** {hype_data['phase']}")
                            
                            # Descripci√≥n de la fase
                            phase_descriptions = {
                                "Innovation Trigger": """
                                    La tecnolog√≠a est√° en su fase inicial de innovaci√≥n. Se caracteriza por:
                                    - Alto nivel de inter√©s y especulaci√≥n
                                    - Pocos casos de implementaci√≥n real
                                    - Gran potencial percibido
                                """,
                                "Peak of Inflated Expectations": """
                                    La tecnolog√≠a est√° en su punto m√°ximo de expectativas. Se observa:
                                    - M√°xima cobertura medi√°tica
                                    - Altas expectativas de mercado
                                    - Posible sobreestimaci√≥n de capacidades
                                """,
                                "Trough of Disillusionment": """
                                    La tecnolog√≠a est√° atravesando una fase de desilusi√≥n. Caracterizada por:
                                    - Disminuci√≥n del inter√©s inicial
                                    - Identificaci√≥n de limitaciones reales
                                    - Reevaluaci√≥n de expectativas
                                """,
                                "Slope of Enlightenment": """
                                    La tecnolog√≠a est√° madurando hacia una comprensi√≥n realista. Se observa:
                                    - Casos de uso bien definidos
                                    - Beneficios comprobados
                                    - Adopci√≥n m√°s estrat√©gica
                                """,
                                "Plateau of Productivity": """
                                    La tecnolog√≠a ha alcanzado un nivel de madurez estable. Caracterizada por:
                                    - Adopci√≥n generalizada
                                    - Beneficios claramente demostrados
                                    - Implementaci√≥n sistem√°tica
                                """
                            }
                            
                            st.info(phase_descriptions[hype_data['phase']])
                            
                            # Mostrar gr√°fico del Hype Cycle
                            fig = news_analyzer.plot_hype_cycle(hype_data, topics)
                            st.plotly_chart(fig, use_container_width=True)

                            # An√°lisis de puntos de inflexi√≥n
                            st.write("### üìä An√°lisis de Puntos de Inflexi√≥n")
                            inflection_points = news_analyzer.analyze_gartner_points(hype_data['yearly_stats'])
                            inflection_fig = news_analyzer.plot_gartner_analysis(
                                hype_data['yearly_stats'], 
                                inflection_points
                            )
                            st.plotly_chart(inflection_fig, use_container_width=True)
                            
                            
                            # Mostrar resultados detallados
                            news_analyzer.display_advanced_analysis(serp_results, query_info, st)
                            news_analyzer.display_results(serp_results, st)
                              
                        else:
                            st.warning("No se pudo generar el an√°lisis del Hype Cycle con los datos disponibles")
                    else:
                        st.error("No se pudieron obtener datos de SerpAPI para el an√°lisis del Hype Cycle")

if __name__ == "__main__":
    main()