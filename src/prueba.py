# An√°lisis de Publicaciones sobre Harina de Pl√°tano y Enzimas por A√±o
# B√∫squeda en Scopus API

import requests
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import time
from datetime import datetime
import re

# Configuraci√≥n visual
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (14, 7)
plt.rcParams['font.size'] = 12

# Configuraci√≥n de la API key
api_key = "113f57bcfb9e922c5a33ec02233ee24d"

def search_plantain_flour_publications():
    """
    Busca publicaciones relacionadas con harina de pl√°tano y enzimas.
    Recopila resultados por a√±o desde los m√°s antiguos.
    """
    print("=" * 60)
    print("üîç AN√ÅLISIS DE PUBLICACIONES: HARINA DE PL√ÅTANO Y ENZIMAS")
    print("=" * 60)
    
    # Corregir la ecuaci√≥n de b√∫squeda (TITLE en lugar de TITTLE)
    query = 'TITLE("Plantain" OR "banana" OR "musa") AND TITLE("flour" OR "starch") AND TITLE("enzyme" OR "glucose oxidase")'
    
    print(f"üìù Ecuaci√≥n de b√∫squeda: {query}")
    
    # Configurar par√°metros de b√∫squeda
    base_url = "https://api.elsevier.com/content/search/scopus"
    headers = {
        "X-ELS-APIKey": api_key,
        "Accept": "application/json"
    }
    
    # Primero, obtener todos los resultados para conocer el rango de a√±os
    try:
        # Verificar si la b√∫squeda funciona
        response = requests.get(
            base_url,
            headers=headers,
            params={"query": query, "count": 1}
        )
        
        if response.status_code != 200:
            print(f"‚ùå Error en la b√∫squeda: {response.status_code}")
            print(response.text)
            
            # Probar con una versi√≥n simplificada de la consulta para diagnosticar
            print("\nüîç Probando con b√∫squeda simplificada...")
            simple_query = 'TITLE("banana") AND TITLE("flour")'
            response = requests.get(
                base_url,
                headers=headers,
                params={"query": simple_query, "count": 1}
            )
            
            if response.status_code == 200:
                print("‚úÖ La b√∫squeda simplificada funciona")
                print("‚ùó El problema est√° en la complejidad de la ecuaci√≥n original")
                
                # Usar la ecuaci√≥n simplificada
                query = simple_query
                print(f"üìù Nueva ecuaci√≥n de b√∫squeda: {query}")
            else:
                print(f"‚ùå Error tambi√©n con b√∫squeda simplificada: {response.status_code}")
                return None
        
        # Realizar la b√∫squeda con la ecuaci√≥n (original o simplificada)
        print("\nüîç Obteniendo resultados completos...")
        response = requests.get(
            base_url,
            headers=headers,
            params={"query": query, "count": 25, "sort": "coverDate"}
        )
        
        if response.status_code == 200:
            data = response.json()
            total_results = int(data["search-results"]["opensearch:totalResults"])
            print(f"‚úÖ B√∫squeda exitosa: {total_results} resultados totales")
            
            if total_results == 0:
                print("‚ùå No se encontraron resultados con esta ecuaci√≥n")
                return None
            
            # Recopilar todos los resultados
            all_results = []
            params = {"query": query, "count": 25, "start": 0, "sort": "coverDate"}
            
            while params["start"] < total_results:
                response = requests.get(base_url, headers=headers, params=params)
                
                if response.status_code == 200:
                    data = response.json()
                    entries = data["search-results"].get("entry", [])
                    all_results.extend(entries)
                    
                    print(f"‚è≥ Recuperados {len(all_results)} de {total_results} resultados ({(len(all_results)/total_results*100):.1f}%)...")
                    
                    params["start"] += params["count"]
                    
                    if params["start"] < total_results:
                        time.sleep(0.5)  # peque√±a pausa entre solicitudes
                else:
                    print(f"‚ùå Error al recuperar p√°gina: {response.status_code}")
                    break
            
            print(f"‚úÖ Recuperados {len(all_results)} resultados en total")
            
            # Analizar por a√±o
            publications_by_year = {}
            
            for entry in all_results:
                # Intentar extraer el a√±o
                year = None
                
                # De la fecha de cobertura
                if "prism:coverDate" in entry:
                    try:
                        date_str = entry["prism:coverDate"]
                        year = datetime.strptime(date_str, "%Y-%m-%d").year
                    except Exception:
                        pass
                
                # Del a√±o de publicaci√≥n
                if not year and "prism:publicationDate" in entry:
                    try:
                        date_str = entry["prism:publicationDate"]
                        year = datetime.strptime(date_str, "%Y-%m-%d").year
                    except Exception:
                        pass
                
                # De la fecha de cobertura (display)
                if not year and "prism:coverDisplayDate" in entry:
                    try:
                        year_str = entry["prism:coverDisplayDate"]
                        year_match = re.search(r'\b(19|20)\d{2}\b', year_str)
                        if year_match:
                            year = int(year_match.group(0))
                    except Exception:
                        pass
                
                # Si no se pudo determinar el a√±o, continuar
                if not year:
                    continue
                
                # Incrementar contador para este a√±o
                publications_by_year[year] = publications_by_year.get(year, 0) + 1
            
            # Crear DataFrame ordenado por a√±o
            if publications_by_year:
                years = sorted(publications_by_year.keys())
                counts = [publications_by_year[year] for year in years]
                
                df = pd.DataFrame({
                    'A√±o': years,
                    'Publicaciones': counts
                })
                
                # Calcular acumulado
                df['Acumulado'] = df['Publicaciones'].cumsum()
                
                # Mostrar tabla completa
                print("\nüìã TABLA DE RESULTADOS POR A√ëO:")
                print("-" * 40)
                print(df.to_string(index=False))
                print("-" * 40)
                print(f"Total de publicaciones: {df['Publicaciones'].sum()}")
                
                # Generar visualizaciones
                create_visualizations(df, query)
                
                return df
            else:
                print("‚ùå No se pudieron categorizar las publicaciones por a√±o")
                return None
        else:
            print(f"‚ùå Error en la b√∫squeda: {response.status_code}")
            print(response.text)
            return None
    except Exception as e:
        print(f"‚ùå Error inesperado: {str(e)}")
        return None

def create_visualizations(df, query_description):
    """
    Crea visualizaciones de los datos de publicaciones.
    
    Args:
        df: DataFrame con datos por a√±o
        query_description: Descripci√≥n de la b√∫squeda para t√≠tulos
    """
    title_base = "Publicaciones sobre Harina de Pl√°tano y Enzimas"
    
    # 1. Gr√°fico de barras
    plt.figure(figsize=(14, 7))
    ax = sns.barplot(x='A√±o', y='Publicaciones', data=df, color='forestgreen')
    
    plt.title(f'{title_base} por A√±o', fontsize=16, pad=20)
    plt.xlabel('A√±o', fontsize=14)
    plt.ylabel('N√∫mero de Publicaciones', fontsize=14)
    plt.xticks(rotation=45)
    
    # A√±adir etiquetas con valores
    for i, v in enumerate(df['Publicaciones']):
        ax.text(i, v + 0.1, str(v), ha='center')
    
    plt.tight_layout()
    plt.show()
    
    # 2. Curva S (acumulativo)
    plt.figure(figsize=(14, 7))
    ax = sns.lineplot(x='A√±o', y='Acumulado', data=df, marker='o', markersize=8, linewidth=2, color='darkorange')
    
    plt.title(f'{title_base} - Acumulado (Curva S)', fontsize=16, pad=20)
    plt.xlabel('A√±o', fontsize=14)
    plt.ylabel('Publicaciones Acumuladas', fontsize=14)
    plt.xticks(rotation=45)
    plt.grid(True, linestyle='--', alpha=0.7)
    
    # A√±adir etiquetas con valores acumulados en puntos clave
    # Primer punto, punto medio y √∫ltimo punto
    indices = [0, len(df) // 2, -1]
    for i in indices:
        ax.text(df.index[i], df['Acumulado'].iloc[i] + 0.3, 
                str(df['Acumulado'].iloc[i]), ha='center')
    
    plt.tight_layout()
    plt.show()
    
    # 3. Gr√°fico combinado
    fig, ax1 = plt.subplots(figsize=(14, 7))
    
    ax1.bar(df['A√±o'], df['Publicaciones'], alpha=0.6, color='forestgreen', label='Publicaciones por a√±o')
    ax1.set_xlabel('A√±o', fontsize=14)
    ax1.set_ylabel('Publicaciones por A√±o', fontsize=14, color='forestgreen')
    ax1.tick_params(axis='y', labelcolor='forestgreen')
    
    ax2 = ax1.twinx()
    ax2.plot(df['A√±o'], df['Acumulado'], color='darkorange', marker='o', linewidth=2, label='Acumulado')
    ax2.set_ylabel('Publicaciones Acumuladas', fontsize=14, color='darkorange')
    ax2.tick_params(axis='y', labelcolor='darkorange')
    
    plt.title(f'{title_base}: Anual vs. Acumulado', fontsize=16, pad=20)
    fig.tight_layout()
    
    lines1, labels1 = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')
    
    plt.show()
    
    # Preguntar si quiere exportar
    if input("\n¬øDeseas exportar los resultados a CSV? (s/n): ").lower() == 's':
        filename = "harina_platano_enzimas_publicaciones.csv"
        df.to_csv(filename, index=False)
        print(f"\n‚úÖ Datos exportados a '{filename}'")
        
        # Si estamos en Colab, ofrecer descarga
        try:
            from google.colab import files
            files.download(filename)
            print("‚úÖ Archivo disponible para descarga")
        except ImportError:
            pass  # No estamos en Colab

# Ejecutar la b√∫squeda
search_plantain_flour_publications()